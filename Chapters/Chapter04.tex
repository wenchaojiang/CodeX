%************************************************
\chapter{AtomicOrchid Study 1: Non agent version}\label{ch:studyone} % $\mathbb{ZNR}$
%************************************************
In this study, we analyse team interactions in an \acf{AO} game setting which simulates a time-critical distributed task environment in a disaster response operation. This study uses the full manual version of \acf{AO} without automated planning support. Players are provided with basic coordination support including remote text messaging, GPS/map sharing. Interaction analysis is conducted to examine log data and field observations revealing local and remote coordination within the responder team. We generate design implications for automated planning support and uncover requirements that highlight the role of local coordination, decision-making resources, geo-spatial referencing and message handling. \\

\section{Introduction}
%\acf{DR} has been characterised as highly coordinated, time-critical collaborative activities  \cite{Mendonca2007}. Coordination is essential in such settings so that time critical interdependent activities such as search and rescue can be completed in a timely and satisfactory manner \cite{Bradshaw2011}. Opportunity space for building `intelligent' task planning support for  such activities has been recognised by the researchers of \ac{HACS} systems (Section \ref{sec:lraisupport}). However, little study has explored the design space for \ac{HACS} systems to support time-critical coordination settings. Therefore, little is known about the challenges and requirements in building systems to support planning for responder teams in such settings.\\

%Due to the critical nature of the disaster operations, it is hard to design and deploy `intelligent' task planning support in the field before we thoroughly explored the requirements of interaction design. On the other hand, computational simulation of an `intelligent' system is fundamentally insufficient for studying socio-technical issues (Section \ref{sec:sociotech}). 

In this study, we aim to use the version of AtomicOrchid game as a research probe to uncover the requirements and design implication for building `intelligent' coordination support system. The AtomicOrchid game creates a socio-technical setting in which player teams plan and executes spatially distributed tasks (see section \ref{sec:sociotech}). Although \ac{AI} researchers has envisioned that an intelligent agent can support task planning by providing computational optimised task allocations in real-time, we focus on a manual version of AtomicOrchid which does not involve any computational planning support. The primary objective is to unpack how human teams coordinate in the time and space constrained task setting through interaction analysis of behavioural data collected from field trials. In particular, the interaction analysis focuses on two aspects of coordination in \ac{AO}, namely `remote' and `local'. The remote aspect is concerned about the coordination activities across distributed teams and remote HQ, which are typically mediated by computational systems. The local aspects is about coordination within co-located teams, in which face-to-face conversations plays a major role. Drawing on the results of the interaction analysis, we aim to generate design requirements and implications for automated planning support. \\

Additionally, this study also supports our later system development and trials. As the first of three iterative trials in this PhD work, this non-agent trial supports the two later Chapters \ref{ch:studytwo} and \ref{ch:studythree} agent-integrated trials by (1) revealing baseline performance of human coordination without agent support (2) generating design requirements which feed into subsequent refinement of AtomicOrchid. The requirements are critical in that (1) the later studies can use them to recognize non-agent related design factors and (2) it also can inspire the interaction design between agent and responders in later system refinement.  \\

%rephrase
%Findings from the study highlight the social processes in which players organise their coordination tasks locally and remotely. We discuss the division of labour between humans and teams; the interactional problems emerged from the remote coordination. We conclude the paper with a number of emerging interaction design requirements to consider when building planning support systems for human teams, which emphasises on system support for remote coordination. \\

In what follows, we expand on the description of the \ac{AO} system in chapter \ref{ch:approach} with a focus on interfaces and interaction design that are specific to this study. We then present results of the interaction analysis, followed by a discussion of performance implications derived from the results, before we move to design requirements. \\

\section{System Description}\label{sec:study3system}
% ===== how do I split this with Approach chapter
The basic game mechanic and system architecture have been introduced in the chapter \ref{ch:approach}. This section gives a detailed description of the system interface that support coordination between the field responder(FR) and headquarter(HQ) players. \\

% the HQ interface 
In this, study, HQ is manned by 2-3 coordinators. All of the coordinators are provided with a web-based coordination interface (Figure \ref{fig:HQinterface}). The interface gives them an overview of the game status and enable them to communicate with the field responders. \\

% insert image here.
\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study1/webinterface}
  \caption{The HQ interface}
  \label{fig:HQinterface}
\end{figure}

As can be seen in the figure \ref{fig:HQinterface}, the majority of the interface is occupied by a map-based presentation of the game status. Roles and locations of field responders are represented on the map as icons. The field responders can be uniquely identified by their initials shown on the icons. The target types and locations are also shown as icons on the map. Location and intensity of radioactivity is indicated by a heatmap. Health status (health value ranges from 0 to 100) of the field responders is displayed on the right-top panel. A chatbox is placed at the right bottom for HQ to browse and send messages. The messaging system follows a broadcasting model. Everyone can send messages to one public channel, and the messages are visible to every player through the mobile and HQ interface.\\

Field responders are equipped with a mobile responder app providing them with sensing and awareness capabilities (Figure \ref{fig:mobileResponderApp}). There are two tabs in the responder app. The ``map'' tab displays a map showing locations of field responders and targets, which is similar to the map on the HQ interface, except that the radioactvity is not shown. The radiation level of the players` current location is displayed as a Geiger counter reading (shown as a number on the top left of the screen), which ranges from 0 to 100. Health status of the field responder is indicated by a health bar on the right side of the Geiger counter. The chatbox (similar to the one on HQ interface) is placed on the "Messages" tab for the field player to receive and send messages.\\

% the mobile responder app
\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{img/study1/mobileinterface}
  \caption{The mobile responder app}
  \label{fig:mobileResponderApp}
\end{figure}

% move this to the study 1 chapter. 
 %The app shows a reading of radioactivity, their health level based on radioactive exposure, and a GPS-enabled map of the game area with the targets to be collected and the drop off zones for the targets. Icons according to responder roles that additionally have their initials on them can be used to identify individuals. Another tab reveals the messaging widget to broadcast messages to the other field responders, and to headquarters.\\

\section{Study Design}\label{sec:study1procedure}
% ====== checked from COOP, should be fine =======
We ran two AtomicOrchid Game sessions. We describe participants, procedure, session configuration, and methods used to collect and analyse quantitative and qualitative data.\\

Study participants were recruited through posters and emails. A total of 18 participants were recruited; 7 participated in session A and 11 in session B. All participants were reimbursed with 15 pounds for 1.5 hours of study. In session 1, there was 2 HQ player and 5 field players. In session B, there were 8 field players and 3 HQ players. The session A have fewer participants then session  B because fewer participants turned up in the study of session A. Although participants are fewer than expected, we still believe that session A can provide valid observation of organisational conducts in \ac{AO} setting.\\

The majority of participants were students of the local university (Appendix \ref{app:demo1}). Upon arrival in the HQ (set up in a meeting room at the local university), participants were briefed and asked to consent to participate. Roles were randomly assigned to all participants (HQ/field responders: firefighter, medic, transporter, soldier). Field responders were provided with a smartphone; HQ coordinators with a laptop. Game rules and interfaces were introduced, and participants were assisted in setting up their phones and laptop clients. Field responders and HQ coordinators were given 5 minutes to discuss a common game strategy. All field responders were accompanied to the starting point within the designated game area, about 1 minute walk from headquarters.\\

Once field responders were ready to start, HQ sent a ``game start'' message. Gameplay commenced for 30 minutes. A ``Game over'' message by HQ concluded the game. Field responders returned to HQ for the post-game session. A group interview was then conducted, before participants were debriefed and dismissed.\\

The size of the game area on the local university campus is 400 by 400 meters, without heavy traffic (Appendix \ref{app:area1}). The terrain of the game area includes grassland, a lake, buildings, roads, and footpaths and lawns. There are two drop off zones and 16 targets. The pilot study showed that this was a challenging, yet not overwhelming number of targets to collect in a 30 min game session. There were four targets for each of the four target types. The pattern of cloud movement and expansion was the same for both game sessions.\\

As described in chapter \ref{ch:approach}, we took a mixed methods approach to data collection and analysis. Five researchers with camcorders recorded the game play. One researcher recorded action in the HQ, and four other researchers each recorded a field responder team. In addition to video recordings, a semi-structured group interview was conducted aiming at eliciting important decision points, strategies and the overall decision-making process. Time stamped system logs were collected that contained a complete record of the game play, including responders` GPS location, their health status and radioactive exposure, messages, cloud location, locations of target objects and task status. \\

\textbf{Data handling} Firstly, the log data (including remote messages) are handled by a digital replay system to reconstruct the game state (Appendix \ref{app:vis1}) that can be triangulated with video data to support interaction analysis (Section \ref{sec:aprloghandling}). Secondly, to give an overview of how remote messages are used as a coordination resource, we used speech-act theory and the notion of adjacency pairs in linguistics to classify messages sent between and among responders and HQ (Section \ref{sec:aprmsg}).\\

\textbf{Interaction analysis} We focus on the analysis of local field responders` interaction to unpack team coordination, including handling of messages sent by HQ. Video recordings of field action were catalogued to identify sequences (episodes) of interest (\ref{sec:aprloghandling}). Key decision points in teaming and task allocation served to index the episodes. Interesting distinct units of interaction were transcribed and triangulated with log files of relevant game activity for deeper analysis that we present in this chapter. Results of interaction analysis will be presented by detailed episodes of game play, with standard orthographic notations introduced in section \ref{sec:aprIA}. \\

\section{Data analysis and results}
Here, we present findings from interaction analysis supported by message classification that reveal how team coordination was achieved. Overall, responders rescued 7 and 9 targets in sessionS A and B, respectively, out of 16 targets in total per session (Table \ref{tab:gameResults1}). Two players were incapacitated in session A, and 1 player was incapacitated in session B. 117 and 70 messages were sent in sessionS A and B, respectively.\\

\begin{table}[h]
\footnotesize
\begin{tabular}{llll}
\multicolumn{1}{l|}{} & Saved targets & Incapacitated players & Remote messages \\ \hline
\multicolumn{1}{l|}{Session A} & 7 (out of 16) & 2                    & 117             \\ 
\multicolumn{1}{l|}{Session B} & 9 (out of 16) & 1                    & 70              \\ 
\end{tabular}
\caption{Overview of game results}
\label{tab:gameResults1}
\end{table}


In what follows, results of the message classification will be presented first, followed by detailed analysis of episodes.\\

% this is from COOP paper, need to adapt it for this writing 
%{An overview shows that directives from HQ are frequently not brought up locally. A further episode demonstrates how field responders instead draw on technological and embodied resources to achieve local coordination, without HQ involve- ment. Finally, two more examples illustrate how responders routinely employ messages as a resource to support situational awareness.\\ %}

\subsection{Results of message classification}
We used Searle`s classification (Section \ref{sec:aprmsg}) of speech acts to categorize messages (Table \ref{tab:speechact}). The table \ref{tab:speechact} shows that the majority of massages are directives and assertives sent by HQ. The majority of messages from field responders are requests for information, team and tasks. In what follows, we present examples for each category of speech acts, which in turn, provide an overview of remote coordination that is supported by the remote messaging system. \\

\begin{table}[h]
\footnotesize
\begin{tabular}{lllllp{5cm}l}
Speech acts  & \multicolumn{2}{l}{Session A} & \multicolumn{2}{l}{Session B} & \multicolumn{1}{c}{Example} & Total    \\ \hline
             & HQ            & FR            & HQ            & FR            &                                                                            &          \\ \hline
Directives   & 57            & 0             & 32            & 0             & JH pair p with BR to save animal in between TA centre and national college & 89(47)\% \\
Assertives   & 25            & 2             & 8             & 4             &                                                                        The leak around geospatial is bigger & 39(20)\% \\
Expressives  & 5             & 0             & 0             & 0             &                                                                           Good Job, JJ, TV and RL & 5(2\%)   \\
Declarations & 3             & 0             & 0             & 0             &                                                                           NOTICE - TEAM B: NS + TD & 3(1.6\%) \\
Commissives  & 0             & 4             & 0             & 4             &                                                                           ok got it & 8(4\%)   \\
Requests     & 8             & 6             & 0             & 19            &                                                                           wheres the leak? & 34(18\%) \\
Unclassified & \multicolumn{2}{c}{7}         & \multicolumn{2}{c}{2}         &                                                                            & 9(5\%)  
\end{tabular}
\caption{Speech act classification}
\label{tab:speechact}
\end{table}

\subsubsection{Directives}

Most messages in the category of directives are instructions sent by headquarter (HQ) players. The content of instructions can be related to two themes: task allocation and task execution. The purpose of task allocation instructions is to distribute plans to field teams and require them to execute it. Most instructions in this category follow a common pattern. Taking the following message as example:\\

\begin{quote}
\texttt{``HQ : JH1 pair up with BR to save animal inbetwen TA centre and national college''}\\
\end{quote}

The instruction sent from HQ consists of two parts: (1) Description of Teaming (who are involved) (2) Description of Location (Targets) to go to. It is worth mentioning that HQ players use different strategies when they try to describe a location to field players. HQ players in session B frequently referred to landmarks on the map in their description, while HQ in session A used simple directions (north, west, south, east). For example:\\

\begin{quote}
\texttt{``HQ: TEAM A, can you head south to the radiation and animal targets? ''} \\
\end{quote}

The purpose of task execution instructions is to help players execute their tasks after they have been assigned tasks. Most instructions in this category are related to radioactive cloud. To help field players avoid the radioactive clouds, HQ players frequently send directions to field players or simply urge field players to move quicker. For example:

\begin{quote}
\texttt{``TEAM B you need to be quick''} \\
\end{quote}

\subsubsection{Assertives}

Assertives provide plain information to recipients. Most assertives are sent by HQ because they have access to critical information - the cloud location. Followings are two examples of assertives:\\

\begin{quote}
\texttt{``the leak around nottingham geospatial is bigger''}\\
\end{quote}

\begin{quote}
\texttt{``HQ:There's another leak by the lake!''}\\
\end{quote}

Interaction analysis shows that assertives are important for field players to maintain situational awareness. We will talk more about this shortly in the section \ref{sec:study1awareness}.\\

\subsubsection{Commissives, expressives and declarations}
We also identified a small number of commissives, expressives and declarations. Commissives are field player`s responses to an assertive or directive. It can be an acknowledgement of receiving a piece of information or commitment to execute a plan. (e.g. ``ok got it'', ``I am heading there''). Expressives are typically HQ`s congratulations to field players. (e.g. ``HQ:Good Job, JJ, TV and RL'' ) In session A, HQ players sometimes declare field players to be in a team (e.g. ``NOTICE - TEAM B: NS + TD''). The declarations help HQ to refer to a team more easily.\\

\subsubsection{Requests and Adjacency pairs}\label{sec:adjpairs}
Here we present adjacency pairs identified in the message logs (Section \ref{sec:aprmsg}). We found a number of requests sent from HQ and field players (14 in session A and 20 in session B). Those requests can be related to a number of themes (Table \ref{tab:requestThemes}).\\

\begin{table}[h]
\footnotesize
\begin{tabular}{l|ll}
                    & \multicolumn{1}{c}{Themes} & \multicolumn{1}{c}{Example}   \\ \hline
\multirow{3}{*}{FR} & Task assignment            & Anything for us to do?        \\
                    & Teaming                    & Firefighter with me for fuel? \\
                    & Cloud info                 & Wheres the leak?              \\ \hline
\multirow{2}{*}{HQ} & Player status              & Firefighter who is free now?  \\
                    & Acknowledgement request    & Firefighter, respond         
\end{tabular}
\caption{Themes of requests}
\label{tab:requestThemes}
\end{table}

In comparison, only a small number of adjacency pairs are found in both sessions (8 in A and 8 in B), which means not all requests are responded to (Table \ref{tab:adjpairs}).\\



\begin{table}[h]
\footnotesize
\begin{tabular}{l|p{3cm}p{3cm}p{3cm}}
          & Total requests & HQ requests/ with no response & FR requests/ with no response \\ \hline
Session A & 14                                 & 8/7                                               & 6/1                                                \\
Session B & 20                                 & 1/0                                               & 19/14                                             
\end{tabular}
\caption{Adjacency pairs}
\label{tab:adjpairs}
\end{table}

It is also worth mentioning that field players didn`t send acknowledgements to directives from headquarter. Although we do not classify directives as a request which expects an answer, the headquarter players express their frustration of not having responses to their instructions. A HQ player said in the group interview:\\
\begin{quote}
\texttt{``I guess they did not look at it, they could not respond it, we were like saying ``where are you, respond'', but they did not respond. I guess they are busy seeing themselves and the targets''}
\end{quote}

A field players also commented on the issue:\\

\begin{quote}
\texttt{``I almost would not use the communication system because I was too focused on trying to save the targets.''}
\end{quote}

\begin{quote}
\texttt{``Sometimes I check whether the radiation is close to us, but mostly the communication is between us (local team members)''}
\end{quote}

\subsubsection{Summary}
To sum up, the majority of messages are assertives and directives from HQ. Directives are instructions sent by HQs as their attempts to guide/control task planning and execution of the team, while the assertives are mainly informational content about status of the danger zone (i.e. the cloud). A small number of commssives, expressives and declarations are also found in the messages. Both HQ and field responders send requests for various purposes (e.g. request for task, teammate, cloud status, confirmations). Based on analysis of adjacency pairs, response rate to the requests are poor, which aligns with the player's comments about their experience of using the message system.

\subsection{Responding to directives from HQ}\label{sec:study1directives}
% TODO introduce episode 2 in my part as a simple unproblematice case here!!
Here, we examine how field responders deal with messages from HQ that attempt to allocate tasks and manage task execution (i.e., directives). Classification of messages showed that directives were exclusively sent by HQ, and that they were the most frequent kind of message (Table \ref{tab:speechact}). Overall, out of the 43 directives HQ sent for task allocation, the recipient field responders brought up only 15 messages in conversation in the team (Figure \ref{fig:study1instructions}). The instances in which task allocation messages were addressed reveal the handling and value of HQ directives in the local coordination. Firstly, out of the 15 task allocation messages responders talked about, they decided to ignore the instructions only once. The responders ignored instructions because they were engaged in another task that they did not want to abandon. Secondly, four HQ instructions to rescue a certain target coincided with the same plan that had already been made locally by the responders. In 10 cases, field responders chose to follow the instructions. However, due to confusion and misunderstanding they failed to follow them correctly six times. In fact, only 2 instances of directives from the HQ led to task completion. For the remaining 14 saved targets, field responders had locally allocated the tasks without HQ.\\

% ===== insert the diagram from the JCSCW paper not COOP
\begin{figure}[h]\label{fig:study1instructions}
  \centering
  \includegraphics[width=1\textwidth]{img/study1/instructions}
  \caption{How responders addressed task allocation messages from HQ.}
  \label{fig:study1instructions}
\end{figure}

Directives index the instances of remote coordination of field responders by HQ. The observed response to messages is critical to understanding the relationships between local and remote coordination. The following episode depicts a team of three on their way to pick up fuel. Their path is blocked by radiation. Without a team, firefighter JH (on the left) has just joined soldier KY (on the right), and firefighter D2 who have just been allocated a task in a message by HQ. (Figure \ref{fig:study1ep11})\\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study1/ep1/ep11}
  \caption{episode 1.1, JH (Behind Left), D2 (Middle Front), KY (Right behind)}
  \label{fig:study1ep11}
\end{figure}


\noindent \texttt{\textbf{Episode 1.1}\\
\textbf{KY:} ((reading out HQ message)) KY and D2, please walk fast to the junction and quickly return back ((laughs))\\
\textbf{D2:} Oh is that what we have to do? Ok so we have to run to (2.0) We need to work out where we have to run to first and then get (.) get it back. Which junction is that? If you run to the next (0.5) thing ((points)), and then come back (1.0) that would work (1.0) is it safer to go around?\\
}


\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study1/ep1/ep12}
  \caption{episode 1.1, KY (Left) , MF (Right) holding mobile phones}
  \label{fig:study1ep12}
\end{figure}


\noindent\texttt{\emph{[The team tries to go around the cloud but is stopped by radiation, realising their target is in the cloud. Meanwhile, D2 has left due to increased exposure.]\\}
\textbf{KY:} So we have to run! [through the radiation] \\
\textbf{JH:} Do we have to run through the (.) through the radiation? ((looking at map)) (Figure \ref{fig:study1ep12})\\
\textbf{KY:} Yah this is what the headquarters told us to do ((looking at messages)) \\
\textbf{JH:} I have a terrible feeling thats gonna kill us.\\
\textbf{KY:} But its gonna be meaningful ((laughs))\\
\textbf{JH:} We go around this corner, if it gets to half [referring to health] we should probably start running back.\\
\emph{ [KY JH begin running into the cloud] } (Figure \ref{fig:study1ep13})
}

\begin{figure}[ht]
\centering
\begin{minipage}[b]{0.45\linewidth}
\includegraphics[width=1\textwidth]{img/study1/ep1/ep13}
\caption{episode 1.1, KY,JH running into cloud}
\label{fig:study1ep13}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
 \includegraphics[width=1\textwidth]{img/study1/ep1/ep14}
\caption{episode 1.1, KY,JH turning around to escape from the cloud}
\label{fig:study1ep1-4}
\end{minipage}
\end{figure}

\noindent\texttt{\textbf{KY:} ((yells)) OH OH! It`s a hundred! [refers to radiation level]\\
\textbf{JH:} We are basically in the middle of it! We are basically in the middle of it!\\
\textbf{KY:} ((shouts)) I`m going back? Get the fuel first! Get the fuel first! Oh no! \\
\textbf{JH:} We are not prepared for that! I blame our HQ.\\
\emph{ [They turn around and run back out of the cloud without the fuel.] }(Figure \ref{fig:study1ep1-4})\\
}

This episode begins with a message by HQ attempting to help give directions to the target. D2`s response to the message is hesitant (`is that what we should do?'). His following question (`which junction is that?') suggests the referent in HQ`s message is not understood. They attempt to go around the radiation. They realise their target is in the cloud. They refer back to the message to support their intent to go into the cloud to attempt to save the target (`Yah this is what the headquarters told us to do'). Having run into the cloud, they refer to the Geiger counter and realise the exposure is too high. Meanwhile, their health is decreasing rapidly. They abandon the task and flee to safely, whilst JH expresses his frustration (`We are not prepared for that. I blame our HQ.').\\

First, the episode shows that geospatial referencing in messages can be problematic. It is unclear to the responders which junction HQ is referencing (and the responders do not ask for clarification), so they revise the route themselves. At the same time, they draw on the messages to justify their entering of the cloud. It does not occur to the responders that HQ allocated the task at an earlier time, before the cloud had covered the target. HQ does not update the responders on the increased danger, or revise their earlier task allocation. When the responder team fails to complete the task, they place blame instead of thinking self-critically.\\

\subsection{Local coordination without HQ}\label{sec:s1localcoordination}
As presented, field responders predominantly coordinated teaming and task allocation without HQ instructions. Recall that 14 targets are saved without HQ's instructions, versus only 2 targets that are saved with HQ's instructions. The following episode illustrates how field responders achieve coordination of teaming and task allocation locally. We join the action as BR and another responder are waiting at the drop-off zone without a compatible teammate, as MF and his teammate join and drop-off their target.\\

\begin{figure}[ht]
\centering
\begin{minipage}[b]{0.45\linewidth}
\includegraphics[width=1\textwidth]{img/study1/ep2/ep21}
\caption{episode 1.2, MF (right), BR (middle)}
\label{fig:study2ep21}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
 \includegraphics[width=1\textwidth]{img/study1/ep2/ep22}
\caption{episode 1.2, MF (right), BR (left)}
\label{fig:study2ep22}
\end{minipage}
\end{figure}

\noindent\texttt{\textbf{Episode 1.2}\\
\emph{[MF (on the right) and teammate walking towards BR (center)]\\}
\textbf{BR:} Any soldiers?\\
\textbf{MF:} I am soldier yeah.\\
\textbf{BR:} Would you like to pair with me? (2.0) to rescue a fuel?\\
\textbf{MF:} what are you after?\\
\textbf{BR:} I am a firefighter.\\
\textbf{MF:} Soldier and firefighter is fuel isn`t it?\\
\textbf{BR:} yeah.\\
\textbf{MF:} What can we get? (2.0) ((looks at screen)) this one in the center? ((points at screen))\\
\textbf{BR:} ((glances MF`s screen)) I think there are two people (the team D2,KY) going for that. I think we should go for this one ((points at screen)).\\
\textbf{MF:} We are going to get killed ((both laugh)).\\
\emph{[The team begins walking to target.]}\\
}

At the beginning of the episode, MF met BR, who was waiting at the drop-off zone without a compatible teammate. BR requested to team up with MF (``Would you like to pair with me? (2.0) to rescue a fuel?'') after MF identified himself as a soldier. BR and MF can then be observed sharing the screen of his device and using the map to identify potential targets (fuels) (Figure \ref{fig:study2ep22}). They realise one of fuel targets is already being pursued by another team. They agree on another target fuel to pursue. Note that messages do not play a role in this episode. It exemplifies how teaming and task allocation are achieved locally, without consulting HQ. \\

The next episode is a follow-up episode, which demonstrates how two teams resolve the conflict when they approach a same target.\\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study1/ep5/ep51}
  \caption{episode 1.3, MF (right), BR (left) met with D2 (middle)}
  \label{fig:intructions}
\end{figure}

\noindent\texttt{\textbf{Episode 1.3}\\
\textbf{D2:} we are told to get this fuel (target 1) from HQ.((pointing to screen))\\
\textbf{MF:} you are going to the fuel (target 1) we are aiming for, we thought you are going for this one (target 2).\\
\textbf{D2:} we were, until we got a message [from HQ] saying not to. \\
\textbf{MF:} you get that one (target 1), we get that one (target 2).((pointing to the two target locations))\\
\textbf{D2:} if you want get that one (target 2). It is somewhere in the building.\\
\emph{[The two teams split, proceed with the new target allocations]}\\}

At the beginning of this episode, the team (BR, MF) has decided to pursue (Episode 1.2) a target other than the one pursued by team D2, KY. However, instructed by HQ, MF and KY changed their target and met BR and MF on the way. The two teams then began to show their intended targets to each other. After they find they are heading to the same target, MF suggested a new allocation of tasks (``you get that one, we get that one.''). D2 then offered some information about the target location to the team MF, BR (``if you want get that one. It is somewhere in the building.''), suggesting he agreed with the new task allocations proposed by MF. \\

The two previous episodes show that how teaming and task allocation are achieved in a seemingly ``ad-hoc'' manner. By using the word `ad hoc', we stress the the actions of field responders are typically not planned ahead to great extend. The players often exchange information through conversations when co-located, and their `plan' is ready to be changed when new information is acquired. Take episode 1.2 as an example, while BR was waiting at the drop-off zone, she requested to team up with MF who happened to pass by. MF agreed to team up and then decided to aim for an available target that had not been aimed at by others. In episode 1.3, the two teams quickly came up with new task allocations when they found they were actually heading to the same targets. In the interview at the end of study, field responders also confirmed their ``ad-hoc'' behaviour in the interview:\\

\begin{quote}
\texttt{``Just save the closest target then just pair up and go to the other one'' }
\end{quote}

\begin{quote}
\texttt{``We just check, with that group, which target we can get. We see on the map to find the closet one we can get.''}
\end{quote}

% Add an episode from my part how the field responder resolve conflicts, suggest it is opportunistic. 



\subsection{Remote messages as a resource of situational awareness} \label{sec:study1awareness}
In the AtomicOrchid game, field responders need to be aware of what other responders are doing, where the `danger zone' is (the cloud), and where it is likely to move. Awareness of each other`s actions helps responders avoid conflicts in planning, while awareness of the danger zone is essential to survive. The following episode illustrates how responders use remote messages as a resource to gain situational awareness.\\

The episode takes place towards the end of game session B. The radioactive cloud has grown so much that navigation in the game area becomes increasingly difficult. MF is with a group of five responders, two of which are carrying an animal. The cloud is blocking their way towards the drop off zone; they stop.\\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study1/ep3/ep31}
  \caption{episode 1.4, MF pointing to a building}
  \label{fig:study1ep31}
\end{figure}

\noindent
\texttt{\textbf{Episode 1.4}\\
\textbf{MF:} ((reads message from HQ out loud)) There is another leak around Geospatial. (1.0) Which is Ah: so there`s a leak sprung up there. ((points)) Geospatial is like (.) that building right there. They say there is another leak. We should go all the way round (0.5) to the top left one, I think. (Figure \ref{fig:study1ep31})\\
}

MF brings up HQ`s message about the new leak, and suggests a route around the new cloud. The group ends up following MF`s route suggestion as a result. News of the new cloud, provided by HQ, enables the group to change their route to avoid danger. We commonly observed responders sharing information that provides situational awareness through face-to-face conversation. In the previous example, MF shared the message with a group of responders he was with already. The following example takes place between D2 and his teammate, as they are approached by JH, who is currently without a teammate.\\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study1/ep4/ep41}
  \caption{episode 1.5, JH (left) met team D2 (male, middle) and KY (female, right)}
  \label{fig:study1ep41}
\end{figure}

\noindent
\texttt{\textbf{Episode 1.5}\\
\textbf{JH:} Where are you guys heading? \\
\textbf{D2:} To get the fuel.\\
\textbf{JH:} Okay. The closest one to you? \\
\textbf{D2:} I believe so.\\
\textbf{JH:} Ya okay cuz I think the leak is somewhere near the other one and the army. [referring to building of Territory Army] (Figure \ref{fig:study1ep41})\\
\textbf{D2:} Oh (.) which one?\\
\textbf{JH:} They sent a message saying its between territorial army center. 
\textbf{D2:} We are trying to get the one here ((points)).\\
\textbf{JH:} The closest one. Okay.\\
}


Making use of the map as he approaches them, JH asks the others to clarify which fuel they intend to pursue (`the closest one to you?'). He proceeds to inform the team that the ``leak is somewhere near the other one''. D2`s response (`Oh, which one?') suggests they did not know this. In turn, JH elaborates on the location of the cloud, using an anonymous ``they'' to refer to the source of his information. ``They'' is likely to refer to HQ as they previously sent a message with the information of the cloud`s location. Conversational sharing of important information was a common resource responders employed to achieve and maintain situational awareness. However, requests for information in the messages channel were regularly not reciprocated with a response: out of 14 requests in session A, 8 were not responded to; and in session B, 14 out of 20 requests were not responded to (Table \ref{tab:adjpairs}).\\

\section{Discussion}
This section will present broader concerns that emerged from the game for the design of automated planning support.\\

\subsection{Division of labour}\label{sec:study1dlabour}
Firstly, the HQ plays an important role in providing situational awareness to the whole team. As the game mechanic provides the HQ exclusive access to the location of the radioactivity, the HQ managed to provide informational messages about the radioactivity to field players. Field players are able to pick up the information and spread it to other field responders through face-to-face conversations (Episode 1.2). Although HQ attempted to organise task allocations directly (through directives), their attempts are often problematic.  Although the field responders did not get too much planning support from HQ, they naturally organise themselves into small teams and carry out tasks. As shown in episode 1.4 and 1.5,  face-to-face conversation was vital for task and team organisation. We observed that co-located team members collectively make sense of the remote messages and game status shown on mobile screens. The decisions such as choices of team, targets and routes are  predominately made through local conversations.\\

The pattern of division of labour between field responders and HQ indicates the weak role of HQ in terms of task planning. The responder's choices of teams and targets seem to follow an ``ad-hoc'' manner as they heavily rely on face-to-face conversation, which can only happen when players are co-located. Despite some disruptions from the communication channel (confusions of geo-referencing, and out-dated HQ messages), field players seem to be able to find team-mates and generally avoid conflicts in their plans (e.g. avoid pursuing the same target) through local coordination. 


\subsection{Breakdown of remote coordination}\label{sec:study1breakdown}
The observed division of labour (Section \ref{sec:study1dlabour}) highlights heavy reliance on local coordination. To some extent, the heavy reliance on ``ad-hoc'' local coordination can partly be a result of the lack of remote coordination support. In other words, local coordination becomes important when system support for remote coordination is problematic. In a co-located setting, players can naturally make their actions observable and accountable to each other through conversations, body languages, gestures , screen sharing etc, and organise coordination activities reflexively. However, in the remote setting, the natural accountability of their activities become opaque. The game probe provides a set of functionalities supporting remote coordination, including GPS/map sharing, broadcasting. We have observed players utilise these functionalities to make sense of other team members' actions (see section \ref{sec:s1localcoordination}) and act accordingly. However, coordination with remote players is still problematic which can be evidenced by the lack of response and acknowledgements to requests in the messaging channel (Section \ref{sec:adjpairs}); and the misunderstanding and confusions observed when field responders try to follow the directives from HQ (Section \ref{sec:study1directives}).\\

We suggest that future planning support should properly support remote coordination in a way that facilitates accountability among distributed team members. Section \ref{sec:study1requirements} discuss some detailed requirements of remote coordination support drawn from the field observations. The next section in particular,  expands on the design requirements that can enhance remote coordination in a way that supports natural accountability of human activities.\\

%{ The natural social order that employed by the team members to make sense of the task environment. Players are observed to constantly revealing to others their action and plans via face to face conversation. CSCW concern that Geo-spatial distribution distributed  hinders team member's attempt maintain accountability . The lack of response in the communication channel shows that. The form of communication in this study appears to be unable to support the team member's accountability. The missing of remote coordination and the weak role of HQ in the planning activities may indicate communication breakdown, which can also be confirmed by a number of observations of understanding and confusions in the communication channel (see x.x.x).\\From this perspective, the domination of local coordination . Some of the reasons? %}

\subsection{Implications on computational support}
%[connect to situated planning by Lucy suchman] it is a kind of situated action. \\
% It is important that we do not treat human plan in an inferir way. They are about to leverage all the resources avalible to make deblibration on their actions. Supporting them a plan will be the same as augmenting their resources. How the team organsie their activities around this resouces can be makde subjuct of study. and study about that can lead to interaction design that support situation

To some extent, the observation of ``ad-hoc'' local coordination is aligned with the view of situated actions. As a whole team, players form and disband teams without holistic plans prior to their actions. Players are observed to have conversations about their status, on-going activities when they meet up. Local decisions for next moves are often made during the conversations.  Information from mobile interface (e.g. player locations, radiation readings and messages) are often brought to conversions as resources in the context of their situated actions. \\

The lack of plans may indicate the lack of optimisation of team task allocation. The multi-agent coordination algorithms (e.g. \citep{Ramchurn2010}) aims to support the team by producing computationally optimised plans for responder teams. However, design of the planning support may not be straightforward. \\

Firstly, there is a danger of imposing an inappropriate ``work model'' (assumed by agent support) on the human team. Studies of \ac{CSCW} systems \citep{Bowers1994} raise a concern that the work model held by the technological system sometimes comes into tension with the natural human workflow achieved through methods internal to the work. In particular, current division of labour between HQ and field responder suggest that HQ plays a supportive role (providing situational awareness). However, a centralized coordination algorithm may need to coordinate the whole team, requiring every player to follow top-down instructions to reach a global optimum of resource allocation. In that case, the role of the control room may need to change and it is unknown whether the change will disrupt or support human workflow. \\

Apart from disruption of human workflow, there is also a danger of the supporting system imposing a planning model on human teams. \cite{Suchman1987} suggests that human's situated action should not be simply treated as a inferior version of scientific planning model. Following the view of situated actions, supporting human's actions are not as simple as providing an optimised plan to execute. A plan for human teams is only one of the resources that humans can utilize for their deliberation on their actions. Therefore, the role for the system is to provide plans (as an extra resource) in a way that supports the human's situated actions. \\

Adopting the view of human agent interaction, we can treat a plan support system as a teamwork agent.  Achieving mutual intelligibility between the agent and the human team can also be a major design challenge. Plans generated by a planning agent can only a representation of possible actions and effects based on simulations. How the responders make use of plans can be highly dependent on situations in which mutual intelligibility plays an important role. For example, it would be problematic if globally optimised choices conflict with the ``ad-hoc'' choices that are obvious for human field responders. We cannot assume either the agent or human choice will be always correct, perhaps neither of them can take an authoritative role. Therefore, we need to carefully design the interaction between human and agent to ensure that they maintain mutual intelligibility so that informed collective decisions can be reached.  \\

%which is often the main concern of multi-agent coordination algorithm. However, the dominance of ``ad-hoc'' local coordination indicates the absence of the notion of resource optimisation. In a sense, it opens opportunity for computational support, but it also highlights some potential challenges for such support system. 


\section{Design Requirements}\label{sec:study1requirements}
Drawing on the problems observed in remote coordination (Section \ref{sec:study1breakdown}), we now discuss the detailed design requirements that enhance remote coordination. The embodied game probe embedded responders in a challenging setting. They needed to communicate effectively to make time critical decisions on teaming and task allocation, both locally in the field as well as remotely through messaging. Field responders physically engage and navigate the environment to perform tasks while maintaining awareness of risk and danger. The data reveals multiple challenges for team coordination involving communication and decision-making. \\

\textbf{Sharing of local decision-making}. The study showed that teaming and task allocation were predominantly organised locally among field responders, in an ``ad-hoc'' manner. Despite the fact that HQ attempted to coordinate task allocation remotely, few of these directives were brought to conversation locally. Only 2 out of 16 tasks that field responders completed were remotely allocated by HQ (Figure \ref{fig:study1instructions}). Although players are able to smoothly conduct local coordination, local coordination heavily relies on and is limited by the face-to-face conversations, which means some conflicts of planning can only be found and resolved when players meet each other (e.g. episode 1.3). Therefore, local decision-making can benefit from a shared picture of team-wide planning decisions. We thus argue that local decision-making needs to integrate capabilities to enable team-wide sharing of the local decisions.\\

\textbf{Coordinate resources}. While field responders made decisions on teaming and task allocation in a seemingly ad hoc fashion, game data reveals how field responders draw on resources to achieve situational awareness in order to coordinate successfully. A common understanding of the location and movement of the radiation cloud was achieved by sharing information from game messages verbally in a local group. Face-to-face talk was an essential resource for relaying information from the Mobile Responder App to teammates, such as radioactive exposure, others` whereabouts, task status, and other monitoring of the broadcast messages. Future planning support systems need to take into account that such coordinate resources are likely to be comprised of digital as well as embodied human resources. \\

\textbf{Geospatial referencing} The results show that geospatial referencing was problematic in various ways, particularly in directive messages sent to the field players. Participants had different levels of knowledge of the campus, which made understanding of landmarks references uncertain. Some participants also struggled with making sense of north/south/east/west directions in relation to their current position and orientation. To deal with misunderstandings, players had to ask for clarification via messages or spend valuable time discussing the reference locally in order to understand it. Consistent with the findings of \cite{Toups2009}, designers need to think carefully about how the presentation layer of such systems may be augmented with information that facilitates geospatial referencing (e.g., grids, labelling etc.) to facilitate human in addition to machine readability. \\

%Freshness of messages. Problems arose from erroneous instructions or otherwise out-dated messages sent to field responders. In one case HQ sent a message in which two players with non-compatible roles were instructed to team up. This was particularly costly, as the players attempted to team up, and lost valuable time until they realised the game mechanics barred them from forming a team.\\

\textbf{Freshness of messages} As demonstrated in one of the episodes, reading out-dated messages in a dynamically changing environment can contribute to responders taking dangerous actions that they believe to be safe, because they do not realise that the information is out-dated. However, in most cases, recipients managed to identify temporally irrelevant messages, and thus avoided following them. To reduce confusion about message freshness, such systems should address these issues at the UI level, both for responders and for HQ. Develop functionality to flag messages as out-dated, to retract incorrect messages, or highlighting up-to-date messages. 

% System support of shared representation of plans and status.

%Thus, our findings support the use of fresh social media as a source of information for disaster response, despite problems that can arise with validation, because crowdsourced information will in many cases provide better coverage than official sources.\\

\textbf{Acknowledgement of messages} In most cases, field responders did not acknowledge or respond to messages sent by the HQ. This was particularly problematic for directives (task allocation), as task status and field responder compliance often had to be inferred by observing their location updates on the map. This consumed HQ attention, with negative impact on HQ`s overall work on state assessment and task planning. Observations in the field suggest that the physical demands (e.g., co-located team movement through terrain at speed) and cognitive demands to maintain situational awareness (e.g., monitoring of radioactivity and messages) are likely factors that explain lack of acknowledgement.\\

%data

As a result, user interfaces that enable and encourage field responders to quickly acknowledge HQ messages, with minimum cognitive load, should be considered for messaging in such systems in such high demand settings. For effective team coordination in disaster response, interface and workflow designs need to factor in cognitive load and task demands for effective information distribution.\\


\section{Summary}
The objective of this study is to unpack how human teams coordinate in the time and space constrained task setting. In particular, we focussed on a scenario in which responders coordinate role-based teaming and spatially distributed task allocation and execution using a real-time location and messaging system, with no automated planning support.\\

We presented the design and study of the AtomicOrchid game as a mixed-reality game probe to investigate challenges for team coordination in a setting in which participants experience both physical strain through bodily activity, and cognitive challenge through time pressure and task complexity. We use mixed-reality game probes as a platform for investigation of concomitant socio-technical issues: handling of mobile devices to communicate and maintain situational awareness (messaging, sensing, interaction, and display) intersect with face-to-face interaction, whilst the physio-cognitive challenges created through game mechanics and environment induce stress. We created a setting that allows exploring requirements to support team coordination of relevance to time-critical coordination domains such as real disaster response.\\

Findings from interaction analysis of field observations, triangulated with log files, reveal how field responders achieved coordination by drawing on local face-to-face conversation with fellow responders, and situational information provided by the interactive map, the Geiger counter, and the messages sent by HQ. Drawing on these findings, we highlight challenges of introducing automated planning support into the socio-technical setting of \ac{AO}. We also generate requirements for supporting team coordination, emphasising the roles of local coordination, decision-making resources, geospatial referencing and message handling. Most of the requirements are feed into the refinements of \ac{AO} system in later studies, which help to reduce influence of non-agent related design factors. \\

% These requirements inform future work on building planning support system by emphasising the role of human interaction in team coordination in time-critical settings.\\

%************************************************
\chapter{AtomicOrchid Study 2: The Human On-the-loop Design}\label{ch:studytwo} % $\mathbb{ZNR}$
%************************************************
This chapter presents the second iteration of AtomicOrchid field trials. In this study, a planning agent is integrated into the system by following a human on-the-loop interaction design, in which the HQs only monitor the planning agent and occasionally intervene. The purpose of the trials is to investigate socio-technical issues related to human agent interaction. Interaction analysis is conducted to examine log data and field observations revealing how human agent interaction plays out, in turn, revealing the process by which players interpret and negotiate the agent`s guidance as well as how these are intertwined with social dynamics of the teams.

\section{Introduction}\label{sec:studytwointroduction}
% Task planning in teams can be complicated by both spatial and temporal constraints, particularly in time-critical task domains such as \acf{DR}. In a \ac{DR} setting, responder teams have to coordinate sparse resources and personnel to prioritize geographically distributed tasks, forming and disbanding teams dynamically to carry out \ac{DR} operations \cite{Chen2005}. Multi-agent researchers have devised a number of agent coordination algorithm to coordinate task allocations for multi-agent systems, which can be adapted to support planning activities of \ac{DR} teams. \\

% However, these algorithms typically model humans as computational agents with respective capabilities, for example to dynamically allocate teams of agents to tasks in order to maximise an objective (e.g., number of lives saved), taking into account other aspects of the real world (environment, infrastructures, victims, etc.) \cite{Ramchurn2010a}. Therefore, the quality of the planning results can be constrained by limited assumptions of human behaviour (e.g., human psychosocial characteristics, movement, and learning ability) and real world environment \cite{Armenakis2012}. These limitations highlight importance of human input in the planning process. Thus, we argue that effective collaboration between human and agent is required to produce and execute high quality plans in the disaster setting. . \\

In order to support effective Human agent collaboration, two patterns of interaction design (Human On-the-loop and In-the-loop) are presented in section \ref{sec:patterns}. In this study, the planning agent is integrated into the AtomicOrchid system with a straightforward Human On-the-loop design (Figure \ref{fig:study2OnTheLoop}). This design assumes minimal Headquarters intervention, that is, the agent can directly interact with field responders to generate and implement plans without constant involvement of HQ. The interaction design is aimed to facilitate a pattern of division of labour, in which a planning agent routinely assigns tasks to distributed responder teams, while human coordinators (the HQ) monitor and support the task execution by responding to arising contingencies. The agent is designed in a way to take into account simple human feedback, i.e., a field responder can either reject or accept their task assignment. The agent will consider the feedback for the next iteration of task assignment.\\

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{img/approach/OnTheLoop}
  \caption{On-the-loop interaction design}
  \label{fig:study2OnTheLoop}
\end{figure}

This study uses the agent integrated version of AtomicOrchid as a probe to unfold socio-technical issues in human-agent interaction, with focus on the implications of the Human On-the-loop design on human team performance. More specifically, this chapter addresses the following research questions on how agent guidance affects the social organisation of team performance:\\

\begin{enumerate}
\item How do human teams respond to being instructed by an agent, particularly on switching teams and tasks?\\
\item The planning agent makes decisions based on limited assumptions about human behaviour, but what are the hidden costs of human behaviour that the agent does not take into account?\\
\end{enumerate}

Findings from the study highlight the social processes in which members interpret, negotiate, and manage the agent guidance within the social dynamics of teams. We discuss the division of labour between humans and teams and the hidden costs of instructions that suggest team reformation and interrupt on-going tasks. We conclude this chapter with a number of emerging interaction design recommendations to consider when building planning support systems for human teams, which emphasises the need for common ground between humans and the agent, facilitate accountability between team members, and balance responsibilities between humans and the planning agent appropriately.\\


% ===== from CTS need adaptation =====
%We present a field trial of how instructions from an intelligent planning agent are dealt with by distributed human teams, in a time-critical task setting created through a mixed-reality game. We conduct interaction analysis to examine video recorded field observations and game log data. The findings highlight the social process by which players interpret and negotiate the agent guidance as well as how these are intertwined with social dynamics of the teams. The insights can be used to develop an understanding of interactional issues around automated team instructions and inform the design of human-centred planning support systems. \\

%Task planning in teams can be complicated by both spatial and temporal constraints, particularly in time-critical task domains such as disaster response (DR). In a DR setting, responder teams have to coordinate sparse resources and personnel to prioritize geographically distributed tasks, forming and disbanding teams dynamically to carry out DR operations [4]. For example, teams of fire fighters and medics are required to extinguish a fire and to provide first aid, while teams of soldiers and transporters may be needed to clear rubble. These teams, in turn, may need to disband and reform dynamically to perform new tasks and to adapt their planning to uncertainties in real time. Whilst an `optimal' plan of team formation and task allocation may help minimise loss of lives and properties, making optimal plans in real time can be complicated and time-consuming due to large numbers of incidents and responders. To address such coordination challenges, multi-agent research has developed a number of smart coalition formation algorithms to computationally support planning in time-critical task settings [3,16]. These algorithms typically model humans as computational agents with respective capabilities, for example to dynamically allocate teams of agents to tasks in order to maximise an objective (e.g., number of lives saved), taking into account other aspects of the real world (environment, infrastructures, victims, etc.) [14]. \\

%However, most of these smart algorithms are based on limited assumptions about human behaviour (e.g., human psychosocial characteristics, movement, and learning ability) [18], and have only been evaluated in computational simulations. In our work, we investigate agent-based planning support in the real world. Specifically, we study the social implications of the division of labour between agents and real human teams. In more detail, while coalition formation assumes leaving and joining new teams as an unproblematic process, we study in depth the social, interactional consequences of agent-based instructions that require team formation. For example, Personal preference and social norms may imply that dynamic team formations have a hidden social cost that may impact team performance. \\

%We present AtomicOrchid, a mixed-reality game probe of the ways in which human teams respond to agent guidance. The probe is designed to create a socio-technical setting in which distributed teams and a planning agent work collectively to save locally dispersed targets on the ground. The planning agent runs a coalition formation algorithm to help allocate tasks optimally to the teams. Our analysis reveals social implications of agent support for human teams. In turn, implications for interaction design are discussed that may improve team performance. More specifically, this paper addresses the following research questions on how agent guidance affects the social organisation of team performance:\\

%How does division of labour play out between humans and agents and how should it be scaffolded by design? 
%How do human teams respond to being instructed by an agent, particularly on joining and leaving teams?
%The planning agent makes decisions based on limited assumptions about human behaviour, but what are the hidden costs of human behaviour that %the agent does not take into account?\\

%Findings from the study highlight the social processes in which members interpret, negotiate, and manage the agent guidance within the social dynamics of teams. We discuss the division of labour between humans and teams; the hidden costs of instructions that suggest team reformation and interrupt on-going tasks. We conclude the paper with a number of emerging interaction design recommendations to consider when building agent-based support systems for human teams, which emphasise the need for common ground between humans and the agent, facilitate accountability between team members, and balance responsibilities between humans and the planning agent appropriately. 

\section{System Evolution}\label{sec:studytwosystem}
Compared to study 1 (Chapter \ref{ch:studyone}), the system has evolved to provide agent planning support with an On-the-loop interaction pattern. This section gives a description of the changes of system, which covers integration of a planning agent, implementation of a quick feedback system, and improvement in both HQ and mobile interface.

\subsection{The planning agent}\label{sec:studyoneagent}
One major change of the system is the integration of a planning agent into the AtomicOrchid platform. The planning agent is developed by ORCHID research partner Wu Feng, Savapali Ramchum, and detailed in section \ref{sec:appagent}. \\

%The coordination problem (Section \ref{sec:gameRatinale}) of the AtomicOrchid is modelled using a Multi-Agent Markov Decision Process (MMDP) that captures the uncertainties of task execution, extending earlier work \cite{Ramchurn2010}. The modelling allows responder actions to be delayed or to fail during the rescue process. The MMDP modelling leads to a large search space, even with a small-sized problem. Hence, we devised an approximate solution to save computation time, which can be executed to support real time planning \cite{Wu2015}. The planning algorithm takes into account both time (cloud and human movement speed) and spatial (path planning for responders) constraints. The planning algorithm run by the planning agent produces high quality task allocations that minimise the travelling distance of first responders, and maximise the number of targets rescued. Before the agent was deployed to support human teams in the game setting, computational simulations were done by Wu Feng to benchmark our MMDP algorithm against greedy and myopic methods (Table  \ref{tab:alg}). The results confirm that our algorithm produces efficient task allocations.\\

The planner, implemented by Java, is wrapped in a PHP server framework and deployed on an independent server separate from AtomicOrchid. The planner server exposes a HTTP interface for AtomicOrchid to request plan. Each plan request issued by AtomicOrchid is appended with updated game status, which includes players' health, distribution of radioactive cloud and locations of players, and targets. Based on the updated game status, the agent will produce an optimised task allocation and return it to AtomicOrchid. The plan requests are triggered frequently in game sessions so that the task allocation can be frequently adjusted according to task execution status. In this study, plan requests (and thus re-planning) is triggered by two kinds of game events:\\


\begin{enumerate}
\item Completion of task. On successful rescue of a target, a new plan (i.e., allocation of tasks to each responder) is requested from the agent.\\

\item Explicit reject. On rejection of a task allocation by any of the first responders, a new plan is requested.  The feature of rejection is part of a feedback loop between human and agent, at will be introduced in next section.\\

\end{enumerate}

\subsection{A feedback loop}\label{sec:study2feedback}
The feedback system is part of the On-the-loop interaction design, which enables the agent to take into account simple human feedback. It is also partly inspired by a requirement generated in study 1, which highlights the importance quick acknowledgements from field responders. The feedback system can be seen as a system mechanism for the field team to provide quick responses to the planning agent. This section goes through the implementation details of the feedback loop.\\

Once a plan is received from the agent, the AtomicOrchid game engine splits the plan for a given team into individual task allocations and sends these to each responder`s mobile app (Figure \ref{fig:handlingplans}). The app displays the task allocation in a pop-up and details it in the task tab, including: i) the responder to team up with, ii) the allocated target (using target id), and iii) the approximate direction of the target (e.g., north, east) (Figure \ref{fig:study2mobiletask}).\\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study2/system/dealingwithplans}
  \caption{Game engine handling plans from agent}
  \label{fig:handlingplans}
\end{figure}

On receiving an instruction from agent, the field responder can choose to either reject or accept the instruction (Figure \ref{fig:study2mobiletask}). In the case of rejection, a new plan will be requested and the agent will consider the feedback for the next iteration of task assignment. More importantly, the rejected allocation is used as a constraint within the optimisation run by the planner agent. For example, if two responders (a medic and a soldier) were allocated a task and the solider rejected it, the planning agent would return a new task allocation with the constraint that this soldier should not be allocated this task. The instructions sent to field responders are also displayed in the HQ interface for monitoring purposes. The task allocations are represented as yellow lines connecting players and their targets (Figure \ref{fig:study2HQ}). Only one task allocation is displayed at one time, HQ player can click on the `show' task button on the player status panel (top right) is to chose whose task to be shown.  \\

\begin{figure}[h]
  \centering
  \fbox{\includegraphics[width=0.4\textwidth]{img/study2/system/mobiletask}}
  \caption{Mobile task interface in study 2}
  \label{fig:study2mobiletask}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study2/system/HQ}
  \caption{HQ and mobile interfaces in study 2}
  \label{fig:study2HQ}
\end{figure}


\subsection{Interface improvements}\label{sec:studytwointerface}
Apart from the agent integration and feedback system, two small modification of the interface were inspired by the requirements generated in the previous study (Section \ref{sec:study1requirements}). Firstly, all icons of targets are now marked by a unique target number for HQ and field responders to cross-reference. Secondly, all the messages are labelled by timestamps for players to help identify outdated messages (Figure \ref{fig:study2mobilemsg}).\\

\begin{figure}[h]
  \centering
  \includegraphics[width=0.4\textwidth]{img/study2/system/mobilemsg}
  \caption{Mobile message interface in study 2}
  \label{fig:study2mobilemsg}
\end{figure}

\section{Study Design}
Study participants were recruited through posters and emails. A total of 18 participants were recruited for 2 sessions of Game play (Appendix \ref{app:demo2}). For each session, there was 1 HQ player and 8 field players. All participants were reimbursed with 15 pounds for 1.5 hours of study. The majority of participants were researchers and students of the local university. The procedure of study is the same as the one described in study 1 (Section \ref{sec:study1procedure} )\\

The game area was the same as for study 1 on the local university campus (Appendix \ref{app:area2}), 400 by 400 meters, without heavy traffic. The terrain of the game area includes grassland, a lake, buildings, roads, and footpaths and lawns. There are two drop off zones and 16 targets. There were four targets for each of the four target types. The pattern of cloud movement and expansion was the same for both game sessions, and it is the same as for study 1.\\

%In this study, we aimed to probe a straightforward [interaction design] between a planning support agent and human teams (Fig. 1). The interactional design is designed to facilitate the division of labour between humans and agent: a planning agent routinely assigns tasks to distributed responder teams, while human coordinators (the HQ) monitor and support the task execution by responding to arising contingencies. The agent is designed in a way to take into account simple human feedback, i.e., a field responder can either reject or accept their task assignment. The agent will consider the feedback for the next iteration of task assignment. \\

%By examining the socially organised interaction between team members occasioned by this interactional arrangement, we aimed to explore social implications of human-agent interaction. In turn, these inform the design of agent-based systems. In the following, we describe the study in detail. \\

%A real-time algorithm was developed to support the coordination problem created by the game mechanic. The coordination problem (described in IV, A) is modelled using a Multi-Agent Markov Decision Process (MMDP) that captures the uncertainties of task execution, extending earlier work [15]. The modelling allows responder actions to be delayed or to fail during the rescue process. The MMDP modelling leads to a large search space, even with a small-sized problem. Hence, we devised an approximate solution to save computation time, which can be executed to support real time planning. The planning algorithm takes into account both time (cloud and human movement speed) and spatial (path planning for responders) constraints. The planning algorithm run by the planning agent produces high task allocations that minimise the travelling distance of first responders, and maximise the number of targets rescued. Before the agent was deployed to support human teams in the game setting, computational simulations were used to benchmark our MMDP algorithm against greedy and myopic methods (see Table 1). The results confirm that our algorithm produces efficient task allocations. \\

%In their mission to rescue all the targets from the disaster space, a centrally located HQ and the planning agent support the responders on the ground. In what follows, we present the player interfaces and the interactions with the planning agent. A demo video can be viewed at http://bit.ly/1ebNYty.\\

%First responders are equipped with a mobile responder tool (Fig. 2) providing sensing and awareness capabilities in three tabs (Geiger counter, map, messaging and tasks). The first tab shows a reading of radioactivity, player health level (based on exposure), and a GPS-enabled map of the game area to locate fellow responders, the targets to be rescued and their drop off zones. The second tab provides a broadcast interface to message fellow first responders and the HQ. The third tab shows the team and task allocation dynamically provided by the agent that can be accepted or rejected. Notifications are used to alert both to new messages and task allocations.\\

%HQ controls the HQ dashboard that provides an overview of the game area, including responders real-time locations (Fig. 2). The dashboard provides a broadcast messaging widget, and a player status widget so that the responders exposure and health levels can be monitored. HQ can further monitor the current team and task allocations to individual responders by the planning agent (by using buttons in the player status widget). Crucially, only HQ can see the radioactive cloud, graphically depicted as a heatmap. The rationale was to entice frequent communication between field responders and HQ.  \\

\section{Data analysis and results}\label{sec:study2analysis}
Here, we present findings from interaction analysis that reveal how team coordination was achieved. Overall, responders rescued 12 and 11 targets in sessions A and B respectively, out of 16 targets in total per session. No player was incapacitated in the two sessions. The planning agent sent a total of 51 instructions (Figure \ref{fig:study2agentInstructions}), 24 of which are accepted and 11 of them are rejected. The remaining 16 instructions do not receive complete responses (at least one of the player did not reply). A total of 21 instructions were finished successfully, versus only 2 of the targets are saved without agent instructions. Of the the 19 instructions that were unsuccessful, some were ignored or violated by players and some were overridden by the agent in the replanning process due to change of circumstance.\\

\begin{table}[h]
\footnotesize
\begin{tabular}{llll}
\multicolumn{1}{l|}{} & Saved targets & Incapacitated players & Average Health \\ \hline
\multicolumn{1}{l|}{Session A} & 12 (out of 16) & 0                    & 80/100             \\ 
\multicolumn{1}{l|}{Session B} & 11 (out of 16) & 0                    & 82/100             \\ 
\end{tabular}
\caption{Overview of game results}
\label{tab:gameResults1}
\end{table}

\begin{figure}[ht]
 \includegraphics[width=1\textwidth]{img/study2/system/agentInstructions}
\caption{Overview of agent instructions}
\label{fig:study2agentInstructions}
\end{figure}

In what follows, we presents selected episodes of game play to reveal how teams accomplish the tasks in the rescue mission, particularly focusing on the social organisation of interaction with and around the agent instructions (Appendix \ref{app:vis2}). The order in which we present the episodes follows the common practice of moving from exhibits of typical/unproblematic instances, via more complex/difficult instances, to exhibits that display problematic interaction or even complete breakdowns. The episodes in later sections will be presented with a standard orthographic notation detailed in section \ref{sec:aprIA}.

% In the episodes, players can be uniquely identified by their initials. Targets are denoted by their unique numeric target id. Task assignments from the agent are represented as two initials and one target id connected by a rightward arrow. For example, the notation PC, CR -> 22 means player PC and CR are instructed to team up and go for target 22. A standard orthographic notation \cite{Jordan1995} is complemented by timestamps [0:00], and system messages from remote players and HQ.  

\subsection{Assigning task assignments to existing teams}
The following episode depicts a team of two dropping off a target and planning the next step.\\

\noindent\texttt{\textbf{Episode 2.1}\\
\emph{[0:00] The team dropped off a target.}\\
\textbf{PC:} I think we dropped off now. Ok. \\
\emph{ [0:07] The team receives a new agent instruction: PC, CR -> 22}\\
\textbf{PC:} I have a task now (3.0) ((studying screen)), I need to go with CR to 22. Are you CR? (Figure \ref{fig:study2ep11})\\
\textbf{CR:} Yes.\\
\textbf{PC:} go 22.\\
\textbf{CR:} We have done 22.\\
\textbf{PC:} Oh (1.0), no (2.0) 22 is there ((pointing to direction of 22)), Let`s go ((PC leads the way, they start walking to 22))\\
\textbf{PC:} Right this way. (Figure \ref{fig:study2ep12})\\
\emph{ [0:28] The team finishes the task assigned by the agent.}\\
}

\begin{figure}[ht]
\centering
 \includegraphics[width=0.7\textwidth]{img/study2/ep1/ep11}
\caption{ep 2.1, CR (Left) and PC (Right) studying screen together after drop off.}
\label{fig:study2ep11}
\end{figure}

\begin{figure}[ht]
\centering
 \includegraphics[width=0.7\textwidth]{img/study2/ep1/ep12}
\caption{ep 2.1, PC (Right) leading the way to new target.}
\label{fig:study2ep12}
\end{figure}

At the beginning of this episode, the team (PC, CR) drops off a target at a drop off zone. Player PC vocalises that they have finished the task (``I think we dropped off now. OK'').  After about 7 seconds, PC says she received a new task allocation from the agent (``I have a task now''). PC confirms the initials of the other player (CR), and suggests CR to join her to go for target 22. The action is consistent with the agent instruction (PC, CR -> 22), suggesting that PC has read through the instruction and decided to follow it. CR said that they have already finished target 22 (``We have done 22''), which indicates he is confused about the current task allocation. PC resolves the confusion by pointing in the direction of 22 and repeating to go for it. Later, the team successfully drop off target 22 as instructed by the agent.\\

The episode shows how an agent instruction is brought up and followed by a team in relative straightforward manner. The instruction was delivered immediately after the drop off of a previous target (7 seconds after). PC successfully locates the new target in the instruction and leads the team to pick it up. Although CR is confused at first, PC manages to rectify CR`s mistake and they finish the task successfully. \\

This episode is a typical case of task assignment to existing teams, i.e. the agent sent a new task to a team immediately after they finished their previous task. Out of a total of 51 agent instructions, 23 fall into this category. The rate of compliance is high for these cases of task assignment to existing teams (21 out of 23; 91\%). \\

\subsection{Task assignments involving team reformation}
Unlike episode 2.1, sometimes the agent instruction implies players need to disband and form new teams after finishing their previous task, in order to enact the computationally optimal plan. 10 out of 51 agent instructions fall into this category (Table \ref{tab:compliancerate}). The compliance rate of instructions that require reteaming (50 percent) is substantially lower than compliance of instructions where players can stay in the same teams (91 percent). The following episode depicts a typical case in which team reformation fails.\\

\begin{figure}[ht]
 \includegraphics[width=0.8\textwidth]{img/study2/ep2/ep21}
\caption{episode 2.2, players from left to right: LT, SS, CR, PC. LT  walking around the team, her body orientation suggesting attempts to leave the group.}
\label{fig:study2ep21}
\end{figure}

\noindent\texttt{\textbf{Episode 2.2}\\
\emph{[0:00] After a target drop off, LT and SS joined PC and CR at drop off zone.} \\
\emph{ [0:24] HQ sent message A: LT, if you think you have the stamina to run to 10 around the north of the lake do so now with a firefighter. }\\
\emph{ [0:28] Agent instruction received:  NK, LT -> 16 }\\
\textbf{LT:} They said ((reads out aloud HQ message A)) \\
\emph{[0:35] CR ((facing LT)): Shall we go get 10}\\
\textbf{LT:} Mine is 16. \\
\emph{[0:38] HQ sent message B: Avoid 17 at all costs (...) I`d avoid 10, too.}\\
\textbf{CR:} ((read out HQ message B)) avoid 10 now. \\
\emph{[0:55] New agent instruction received: NW, LT -> 15}\\
\textbf{LT:} 15!\\
\emph{[Fig. 3] LT keeps walking and turning back and forth from others. PC and SS discuss next steps, LT does not engage in the discussion with them. }\\
\emph{[1:12] SS ((facing PC)): Shall we go get 19? ((turning towards LC and CR)) are you going to 10 or something? }\\
\textbf{CR:} Eh::, HQ said no. [referring to message B]\\
\emph{[1:24] SS and PC decide to go for target 19, and leave.}\\
\emph{[1:29] NW sent message: LT where you}\\
\textbf{CR:} ((facing LC)) Are you LT? \\
\textbf{LT:} Yes. \\
\textbf{CR:} NW is looking for you. \\ 
\textbf{LT:} Yah thanks. ((turning away from CR)) Ah::. I will go towards them.  ((starts walking)) \\
\textbf{CR:} Okay. Do you want company?\\
\textbf{LT:} ((turning back towards CR)) Yeah. \\
\emph{CR and LT leave drop off zone together to find NW.}\\
}

The episode begins with a recommendation by HQ to LT to go for 10 (message A). The message is topicalised by LT, but it is soon overridden by an agent instruction (NK, LT -> 16). When CR proposes to team up with LT to go for target 10, LT declined (``mine is 16''). HQ then withdraws its previous suggestion to go for 10 in message B. Shortly after; a new instruction (NW, LT-> 15) prompts LT to read out the target number (15), but she fails to raise the other players attention. While other group members engaged in planning next steps, LT does not engage and keeps looking around. She can be seen turning and walking back and forth (Figure \ref{fig:study2ep21}). Perhaps LT is trying to locate the player NW who she had been instructed to team up with. LT does not take any action until prompted by CR (``are you LT? NW is looking for you''). Then, LT begins to walk to find her teammate. However, when she finally manages to meet up with NW two minutes later, NW has already been assigned another task. \\

On the one hand, LT seems to feel obliged to follow the agent instructions. She turns down other teaming invitations and appears to try to look for NW in her immediate vicinity, indicating difficulty with locating teammates out of sight (despite the real-time location map). On the other hand, her body orientation displays a sense of attachment to the existing group. Her indecisive walking and turning back and forth suggests she is struggling to leave. She does not leave the group to follow the instructions until prompted by someone. When CR points out NW's messages, LT does not answer the message either. The episode illustrates a combination of interactional troubles as a result of which the reteaming fails: being attached to the local group, struggling to locate teammates out of sight, and failing to reciprocate messages. \\

Further, we found the distance between instructed players to be a key factor in successful reteaming. That is to say, if instructed players are not within line of sight, the rate of non-compliance with the agent instruction is high. Take episode 2.2 as an example, player LT was instructed to team up with a distant player twice. Neither one of the instructions was successfully implemented. Overall, there were 17 agent instructions that implied teaming with distant players; only 1 of them were actually followed by players. Players explicitly rejected 11 of them by pressing the rejection button; the other 5 were not followed without an interface action (i.e. neither accepted nor rejected).\\

\subsection{Task assignments involving task interruption}
In some other cases, the agent also sent new instructions to teams that had already commenced their task; that is, teams were interrupted by the new instructions. The following two episodes 2.3 and 2.4 describe how players handled task interruptions caused by the agent.\\

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{img/study2/ep3/ep31}
\caption{episode 2.3, AW (right) leads the way, heading to target 44 as instructed.}
\label{fig:study2ep31}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{img/study2/ep3/ep32}
\caption{episode 2.3, After the team received an instruction to disband, AW (right) and HB (left) simultanously turn back and start walking back to the drop off zone, displaying bodily alignment.}
\label{fig:study2ep32}

\end{figure}

\noindent\texttt{\textbf{Episode 2.3}\\
\emph{ [00:00] HB, AW at drop-off zone, new instruction received: AW, HB->44} \\
\textbf{HB:} Alright, who is AW? \\
\textbf{AW:} Me.\\
\textbf{HB:} let's go southeast (the direction of target 44).\\
\emph{[00:07] AW, HB looking at their screens.}\\
\textbf{[00:26] HB:} There is no 44.\\
\textbf{AW:} down there.\\
\textbf{HB:} Ok, yea, yea, yea (0.5), I can`t see, Oh, there, yea, let`s go.\\
\emph{[00:35] [Fig.4] Team begins moving towards 44.}\\
\emph{[00:48] HQ sent message: Target 42 and 44 is not reachable.} \\
\textbf{AW:} ((reads out the message))\\
\emph{AW and HB stopped walking.}\\
\emph{[00:52] New instructions received: AW, KD -> 44, HB, AR->31}\\
\textbf{AW:} I got a new instruction.\\
\emph{[Figure \ref{fig:study2ep31}] AW and HB simultaneously turn and start walking back towards the drop off zone.}\\
\textbf{HB:} I need to team up with AR.\\
\textbf{AW:} I need to team up with KD! Oh, it is 44 again.\\
\emph{ [01:01] AW, HB arrived at drop off zone, met AR, KD.} \\
\textbf{HB:} AR?\\
\textbf{KD:} AW? We have got (1.0), 44, right?\\
\textbf{AW:} It said 44 is not reachable, but I got it again, so, let`s try.\\
\textbf{KD:} Alright. \\
\emph{[01:14] AW, KD begin walking to 44, AR, HB team up as well.}\\
}



This episode begins with an instruction (AW, HB -> 44) from the agent. At that moment, there were 5 players at the drop off zone (AR, KD, LC, HB, AW). Immediately after the instruction, HB starts looking for AW in the local group. Shortly after, AR and HB team up to go for 44 as instructed.  However, 13 seconds later the team is interrupted with a HQ message telling them not to go for 44 (Target 42 and 44 is not reachable). Four seconds later, a conflicting agent instruction was delivered, implying they disband the team (AW, KD -> 44, HB, AR->31) but still pursue the target 44. At first, AW stops walking and topicalises the instruction (``I got a new instruction''), followed by both teammates simultaneously turning towards each other (Figure \ref{fig:study2ep31}, \ref{fig:study2ep32}). The bodily alignment in the action suggests agreement to follow the new instruction. On their way back to drop off zone, HB and AW confirm their intentions (``I need to team up with AR'', ``I need to team up with KD!''). In this case, the teammates respond to the interruption by mutually agreeing to abandon the current team and task in favour of following the new assignment. \\

It should be noted that the interruption was received only 17 seconds after the team commenced the task, probably contributing to a low perceived cost of abandoning the current task. Further, all players involved in the subsequent reteaming were not far away from each other. AW and HB had not walked far from the drop off zone; so everyone was still within line of sight, further facilitating successful reformation. \\

\subsection{Disagreement on task interruption}

\noindent\texttt{\textbf{Episode 2.4}\\
\emph{[Following on from Episode 2.3]}\\
\emph{AW, KD on their way to target 44.}\\
\emph{[01:39] New instruction received again, AW, HB -> 44, AR, KD ->31}\\
\textbf{AW:} new instruction, HB and 44 again, haha.\\
\emph{AW turns back towards drop off zone immediately.}\\
\textbf{KD:} AR and 31 ((Reading his new instruction)) ehh, have they gone? Because we can just decline and carry on.\\
\textbf{AW:} Ok, I rejected it. \\
\emph{AW turns back towards KD, who also rejects the new instruction. They resume their walk to 44.}\\
\emph{[01:54] New instruction delivered to AW (AW, YF ->46)}\\
\textbf{AW:} new instruction 46, yeah! ((team stop walking))\\
\textbf{KD:} Do they know we are already on the task?\\
\emph{[02:00] New instruction delivered to AW (AW, LC ->37)}\\
\textbf{AW:} yea, but I think, Oh, no, got new instruction again, (team up with) LC.\\
\emph{[02:13] AW starts walking to LC, who is at drop off zone within line of sight, leaving behind KD.}\\
\textbf{KD:} ((reads out HQ message)) AW and KD you won`t reach 44.  Alright, Let`s go to 46.\\
\emph{AW ((turning back towards KD)): I don`t know, I got a new task with LC.}\\
\textbf{KD:} Ahh, I do not have a task. \\
\emph{AW turns and walks towards LC again. KD follows.}\\
}


In this fragment, we can observe disagreement and negotiation of team reformation. Following episode 2.3, player AW disbands his team with HB and teams up with KD. However, 20 seconds after the reformation, AW is instructed to abandon the on-going task again. AW laughs, but turns back to find player HB again. Before AW sets off, KD disagrees with the new instruction and proposes to reject it (``Ehh, have they gone? Because we can just decline and carry on''). AW accepts KDs suggestion and turns back to KD.\\

After the rejection, AW receives 2 consecutive reteaming instructions from the agent, finally teaming them up with LC, while KD does not receive another instruction. KDs question (``Do they know we are already on the task?'') suggests that he might think the agent is unaware of their situation, and that he disagrees with disbanding the existing team. In spite of KDs disagreement, AW declares his intention to follow the new instruction (``got new instruction again, [team up with] LC'') and he turns to find LC. However, KD ignores this (``Alright, Lets go to 46''), indicating he does not agree with AWs intention to disband the team. AW interjects (``I dont know, I got a new task with LC''), and continues to walk towards LC, denying KD. As KD realizes he is without assignment (``Ah, I do not have a task''), he follows AW to find LC. \\

In this episode, teammates agree to reject the first task assignment. We found task interruption could be a major reason to reject new instructions. 10 out of 11 rejected instructions are associated with task interruption. In an extreme case (not pictured), one team reached an agreement to ignore any agent instructions after the agent tried to interrupt the teams` on-going task. \\

In the end, the player that received the new instruction disagrees with his teammates suggestion to ignore the instruction and decides to leave the current team. The team is disbanded in disagreement, in contrast to episode 2.3 where both teammates agree to leave the team after both received new instructions at the same time. Here, the teammates spend a fair amount of time arguing whether to follow or ignore instructions, hinting at the hidden social cost of agent coordination algorithms when applied to human teams. \\

Overall, the majority of new instructions that interrupted on-going tasks required team reformation. When tasks were interrupted, the rate of compliance (22 percent) is substantially lower than when teams were required to reform after a task was completed (50 percent). Task interruptions were also much more likely to lead to rejection of the new assignment: 10 out of 11 assignments that interrupted tasks were rejected.\\

\subsection{The headquarters}

HQ sent a total of 147 messages in the two sessions. We identified 50 assertives and 68 directives in two sessions through speech act analysis \ref{sec:aprmsg}. The majority of assertives were focused on providing situational awareness and safely routing the responders to avoid exposing them to radiation. E.g. ``NK and JL approach drop off 6 by navigating via 10 and 09.'' or ``Radiation cloud is at the east of the National College.''\\

16 out of 68 directives were directly related to task allocations and teaming, which is substantially less then the number of agent instructions (51). Among the 16 directives, HQ sent 11 direct instructions to the field players (e.g. ``SS and LT retrieve 09''), while the remaining 5 are related to forward planning, (e.g., ``DP and SS, as soon as you can head to 20 before the radiation cloud gets there first''). 6 of the HQ instructions are consistent with agent instruction, while 5 other HQ instructions override the agent instructions. It is worth mentioning that field players implemented only 5 out of 16 HQ instructions. In the interview, HQ reported that they felt they supported the agent rather than taking control. \\

%Insert a diagram here.

\section{Discussion}
In the previous sections, we described how the agent guidance is interleaved with social interaction, in which teammates organise the task planning and execution. We found that while the agent supported division of labour, the agent guidance had various social implications. We now reflect on (1) how division of labour is achieved; (2) the social implications and hidden cost incurred by team reformation and task interruption; and (3) the limited feedback mechanism. \\

\subsection{Division of labour between the agent and the human teams}
Overall, players followed 30 out of 51 agent instructions, out of which 21 tasks were completed according to the instruction (success rate of 70 percent). Only 2 targets were evacuated without agent instruction (Figure \ref{fig:study2agentInstructions}), which indicates that, to a large extent, the agent successfully supported routine task planning activities. Episode 2.1 demonstrates a typical case of division of labour: the agent handles planning of teaming and task assignment, freeing the team to focus on other issues such as navigation (identifying the target on the interactive map and finding directions) and organising team meet up.  The following of agent instructions speaks of players trust in the agents decisions. In the 30 cases where instructions were followed, we can observe similar patterns of division of labour.\\

The distribution of HQ messages may also indicate a division of labour between HQ and the agent. Only a small proportion (16 out of 147) is directly related to task assignment, indicating routine task allocations were delegated to the agent. A relatively large proportion (118 out of 147) of messages are used to provide situational awareness and safety routing the responders to avoid radiation exposure. However, the fact that only 5 (out of 16) HQ instructions are implemented suggests that HQ was unable to effectively override the agent when they wanted to. This fact highlights that the planning agent plays a strong role in the control loop, compared to the human coordinators in the HQ. The planning agent can directly instruct field responders without consent of the HQ, and the HQ does not have an effective way of overriding the agents decision. \\

\subsection{Hidden costs of team reformation and task interruption}\label{sec:study2social}
With this division of labour introduced in the previous section, it appears that system can successfully generate plans for humans to ``executes''. However, Following the view of situated actions \citep{Suchman1987}, The plan is actually a resource in the situation that human can leverage or not. In what follows, we reveal the significance of the plan in determining humans`s actions varies based on the social situations the players are in. 

First, while the compliance rate with agent instructions was high when no reteaming was required (91 percent), we found that the rate of compliance with agent instructions is much lower when team reformation is involved (50 percent), and even lower when in addition an on-going task is interrupted (22 percent) (Table \ref{tab:compliancerate}). Our interaction analysis shows the ways in which team reformation and task interruption are associated with hidden costs in the social organisation of team performance.  \\

\begin{table}[h]
\footnotesize
\begin{tabular}{l|ccc}
Context                   & \multicolumn{1}{l}{Instructions} & \multicolumn{1}{l}{Followed by FR} & \multicolumn{1}{l}{Compliance rate} \\ \hline
Instructing existing team & 23                               & 21                                 & 91\%                                \\
Require team reformation  & 10                               & 5                                  & 50\%                                \\
Interrupting tasks        & 18                               & 4                                  & 22\%                                \\
Total                     & 51                               & 30                                 & 59\%                               
\end{tabular}
\caption{Compliance with agent instructions by context}
\label{tab:compliancerate}
\end{table}

We found that team disbanding can be difficult. Players have to make their actions accountable to gracefully disengage from an existing team to avoid breaching social norms (e.g., politeness). Members have displayed a sense of attachment to a local group (episode 2.2), which delayed the task substantially until the team reformation failed. Despite interrupting an on-going task, new instructions for both teammates can facilitate smooth, mutually agreed disbanding (Episode 2.3), while instructions for only one member have coincided with interactional trouble, disagreement and delays (episode 2.4). \\

The impact of attachment between co-located teammates was further amplified by distance between proposed teammates. While they frequently accounted for actions with co-located players, they did not make their actions equally accountable to remote team members. For example in episode 2.4, the agent interrupted the local teams task and instructed them to team up with distant players. The co-located team decided to reject the instruction without contacting the potential teammates they rejected. The system lacked support for accountability between remote members. \\

A further observation is that players were unwilling to give up on-going tasks after a certain time. In episode 2.4, the teammates first agree to ignore new instructions. This preference to stick with on-going tasks may also explain the high rejection rate for instructions involving task interruptions. \\

The social organisation of coordination reveals implications for the simple model of interaction held by the agent. The agents algorithm re-plans and reshuffles teams, in order to optimise group performance by minimising the travel distance to the targets. However, the study has revealed the ways in which social norms and the accountability of social conduct get in the way. This raises questions about the effectiveness of approaches that treat coalition formation of humans as unproblematic. The agent does not consider the social cost of team reformation and task interruption.The study has shown that the social process to disengage from groups and on-going tasks can be costly. The tension between the social process and the model held by the agent echoes the notion of workflow from within and without \citep{Bowers1994}. The authors point out that models imposed by technology (from without) may come into tension with the actual workflow achieved through methods internal to the work (from within). 



\subsection{Feedback to the agent}\label{sec:studytwofeedback}

To recap, a feedback mechanism was included in the interaction design to give responders some control over the task assignment (Section \ref{sec:study2feedback}). On receiving an instruction, players can either accept or reject the instruction. On rejection of a task allocation, a new plan is requested. The rejected allocation is, in turn, used as a constraint within the optimisation run by the planning agent, which means that the rejected target will not be assigned to the rejecting player for a time (1 minute). \\

Our observations show there may be a significant cost associated with rejection. Overall, 6 out of 25 re-plans were triggered by rejections. In turn, tasks were re-assigned to all players (not just for the play who rejected). Frequent new instructions may cause extra coordination overhead (time spent on interpreting new instructions, more team reformation and task interruptions) and over-constrain the planning task. Players did not seem to be aware of the implications that their rejections had on others.\\
 
We also found that players` expectations of the rejection were not always aligned with its actual effect. Instructions involving reformation and interruption were more likely to be rejected. Players` statements indicated that they perceived the rejection as a way to reverse to previous states (Episode 2.4). Other statements indicated rejections were expected to pair them with a new teammate instead of a new target. The mismatch between expected and actual effect highlights a lack of intelligibility in the current interaction design. We aimed at simplicity (by providing only accept/reject options), which might be important for interaction in time-critical task settings, but it comes at the cost of intelligibility. Therefore, we argue that intelligibility and simplicity need to be carefully balanced according to details of the setting.\\


\section{Design implications}

Our observations reveal the tension between agent planning support and the social organisation of teamwork. The tension does not simply mean that the model held by the agent is incorrect; it highlights potential trade-offs we need to consider in system design \citep{Bowers1994,Sukthankar}. Providing a detailed design solution is beyond the scope of this thesis. Instead, we propose three design implications to scaffold the division of labour when building agent-based planning support for human teams.\\

\subsection{Achieve common ground}  
Two main issues arose that challenged the basis for collaboration \citep{Bradshaw2011}. Firstly, a notion of the social cost associated with instructing teams should be taken into account when designing planning agents. For example, disbanding teams can be difficult and time-consuming as it is governed by rules of social conduct and etiquette, particularly where the new teammates are out of sight or only one of the teammates receives a new instruction. Secondly, a mismatch between the expected and actual function of rejections further shows intelligibility needs to be improved. Therefore, we suggest that the design of agent support should a) takes social factors into consideration (e.g., ensuring team disbanding is facilitated by reteaming both teammates at the same time; avoiding task interruptions etc.), and that b) agent functionality is appropriately surfaced to help achieve common ground (e.g., by providing explanations of agent action at the interface level).

\subsection{Facilitate accountability}
While the rules of social conduct ensured accountability of action among co-located teammates, we found the impact of rejections on remote players was not properly appreciated; nor did the interaction design support making these rejections accountable. Therefore, we believe the interaction design should reveal the hidden cost of certain actions (e.g., rejections) to facilitate the accountability of local decision making accountable to remote team members, ensuring consequences of local decisions for the welfare of all teams are understood. 

\subsection{Balance responsibilities between humans and agent}\label{sec:balanceResponsibility}
 The social implications and other situational contingencies are likely difficult to be modelled computationally. Alternative approaches argue for mixed-initiative  control and flexible autonomy between humans and agents \citep{Bradshaw2011}. The ways in which the HQ used messsages to provide situational information that complemented the agent instructions show that humans are able to deal with arising situational contingencies. The division of labour between humans and the agent appeared generally effective in that the agent took on routine and repetitive jobs (task assignment), which freed the responders to focus on the situated rescue mission. In this on-the-loop interaction design, the role of the human HQ was relatively weak. For example, the HQ struggled to override the agents` instructions through the messaging channel. In the next study we explore an in-the-loop design which seeks to allow the HQ to play a stronger role in the control loop to enable more direct mediation and amendment of agent instructions (e.g., by directly modifying the task assignments, or by adding information relating to the assignments, such as safe routing).
 
%==== what is possible situational contingencies? social implications, coordination overhead incured is hard to be modelled, and other unexpected situational contingencies are hard to be considered by the agent. The example being some players is reluctant to disband team and unwilling to team up with remote players. As they are hard to be considered and model by the agent, HQ's input can be useful to judge the situation and contribute to the planning. In this field trial, The division of labour between humans and the agent appeared most effective in that the agent took on routine and repetitive jobs (task assignment), which freed the responders to focus on the situated rescue mission. However, the HQ is weak in terms of influencing the planning and plan executions. The reason has been summaried in section xxx. Here, we propose some requirements based on the.  ====%

\section{Summary}

In this chapter, we examined how the guidance from a planning agent is handled socially in the Human On-the-loop setting. To support our field trial we integrated a planner agent with AtomicOrchid and modified both mobile and HQ interface to facilitate the On-the-loop interaction pattern between human and agent. Findings from interaction analysis of field observations, triangulated with log files, reveal how the On-the-loop interactions played out. The results of the analysis show a division of labour in which the agent takes over the majority of planning activities while field responders only focus on other issues such as finding routes and targets. However, field observations also reveal significant costs associated with instructions that require members to reform new teams, and that interrupt on-going tasks. In addition, some confusions and misunderstanding are also discovered in the human agent feedback loop. Based on the findings, we presented three design implications to consider when creating agent-based planning support systems for human teams, including establishing `Common Ground', facilitating accountability and balancing responsibilities between human and agent.\\


%************************************************
\chapter{AtomicOrchid Study 3: Agent-supported In-the-loop design}\label{ch:studythree} 
%************************************************
This chapter presents the third iteration of the \acf{AO} field trials. The purpose of this iteration is to investigate socio-technical issues relating to agent planning support with a Human In-the-loop interaction design. Based on the On-the-loop version of AtomicOrchid (Section \ref{sec:studytwosystem}), the system has gone through another development iteration to facilitate an in-the-loop interaction pattern. Through interaction analysis of video recordings and game log data, we reveal how this In-the-loop design unfolds and, through a number of critical incidents, how it breaks down. A workshop with a professional disaster response team is conducted to reflect on realism of AtomicOrchid scenario. \\

%and raises the challenge to extend this work to more complex but slower paced situations.   \\

%We find that the human coordinator and automated planner agent can successfully work together in most cases, with human coordinators inspecting and `correcting' the agent-proposed plans. However, occasional failures of planning are also observed due to: complacency; silent, missing or invisible information; and limited support for human planning.

\section{Introduction}
%Most disaster operations require responder teams to plan and carry out task under spatial and time constraints. which means the teams often have limited resource and personnel to deal with large amount of geopolitically distributed tasks in limited amount of time. How do they optimise the use their rescue resources become computationally complicated problem. Multi-agent system researchers have developed a number of multi-agent task allocation algorithms. As software components, they have all done very well in the computational simulation, therefore there is potential to apply those algorithms to support planning activity of human responder teams. \\

%However, these algorithms necessarily depend on abstracted models of the environment and human behaviour which might lead to task allocations that are flawed in practice, due to the contingent nature of situated action \cite{Suchman1987}. 

In this study, we keep refine the \ac{AO} interface and place a human coordinator in-the-loop between the planning algorithm and the physical world. The in-the-loop design pattern assumes the constant HQ supervision and intervention is required to ensure the agent works properly (section \ref{sec:approachPatterns}). The AtomicOrchid system has evolved from the second game probe in study 2 (chapter \ref{ch:studytwo}), to facilitate the In-the-loop interaction. The In-the-loop design enables HQ human to involve in the planning process by: \\

%However, there is concern that the algorithms hold over-simplified model of the environment and human behaviours. Therefore, effective interactions with the responder teams may be required to ensure the planning agent actually support (rather than hinder) the planning process of responder teams, which highlights the importance of appropriate interaction design. 

\begin{enumerate}
	\item allowing HQ to review, edit and approve every instructions generated by agent. (Figure \ref{fig:study2InTheLoop} (1)). In extreme cases, HQ can override all agent instructions, i.e. manually allocate all tasks;
	\item allowing HQ to decide when to initiate re-planning (Figure \ref{fig:study2InTheLoop} (2)); and
	\item allowing HQ to review feedback from field players and decide how to act on them. (Figure \ref{fig:study2InTheLoop} (3))
\end{enumerate}

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study3/InTheLoop}
  \caption{In-the-loop interaction design}
  \label{fig:study2InTheLoop}
\end{figure}

Compared to the human on-the-loop design in the previous study (Section \ref{sec:approachPatterns}, chapter \ref{ch:studyone}) , the major change is the rebalancing of responsibilities in the control room (between HQ and agent). The interaction between field responder and the control room is mostly unchanged. Therefore, this study has a strong focus on control room interaction compared to study 2. More specifically, the objective of this study is to unpack the human agent interaction in the human In-the-loop paradigm, particularly in the control room, revealing division of labour, interactional issues and design implications that can be drawn from the interactions. Findings from the study reveal the processes in which the agent and HQ players collectively generate task assignments for field players. Occasional failures in the process highlights a set of issues including complacency; silent, missing or invisible information; and limited support for human planning. In addition, a workshop with a professional disaster response team is reported in this chapter to reflect on realism of AtomicOrchid scenario. \\


\section{System Evolution}\label{sec:study3system}
The in-the-loop version of AtomicOrchid is not designed from scratch, but evolved from the on-the-loop version introduced in previous study (Section \ref{sec:studytwosystem}). In study 2, we observed HQ struggling to get involved in the planning loop even when they wanted to intervene. Combining the observations from the study 2 and the definition of the in-the-loop interaction pattern (\ref{sec:approachPatterns}), we further generate several system requirements for realizing the In-the-loop interaction. \\
\begin{enumerate}
\item HQ should be able to review, edit and approve every instructions generated by the agent.
\item HQ should be able to decide when the agent should re-plan. 
\item HQ should be able plan for part of the team, leaving the agent to plan for the rest of the team. 
\item HQ should be able to communicate their assignments (or task cancellation) to FRs in a structured way. 
\end{enumerate}

The purpose of requirement 1-2 is to give HQ more control over the planning loop, by delegating to them the responsibility for final decision in planning. Requirement 3 enables HQ to modify the agent planning without having to take full manual control of plan generation. Requirement 4 is derived from the observations (study 1 and 2) that HQ struggled to override agent planning through unstructured text messages. Therefore, we suggest that HQ should be able to deliver and cancel their assignments in the same structured way that the agent do. Two interfaces are designed for the 2 HQ players in the control room. The task assignment interface provides a set of interface functionalities supporting task allocation activities, while the situational awareness interface provides game status and a broadcast message channel \ref{fig:study3messaging}.  \\

% the mobile responder app
\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study3/system/Interfaces}
  \caption{Messaging system design}
  \label{fig:study3messaging}
\end{figure}

%1. Plan request:  HQ can request planner to generate plan (at 1). Agent conducts task optimization based on current task status, and proposed on optimal plan to HQ for review.\\
%2. Plan review: HQ can choose make some minor edits to agent proposed plan. Alternatively, the HQ can propose some assignments, and re-initiate step (1) to let the agent conduct partial planning for the rest of the team (explain for partial planning, see section x). \\
%3. Plan approval: If HQ is satisfied with the plan, he/she can send the plan to field responders for execution. \\
%4. Feedback and further communication: When Field responders receive plans, they can communicate with HQ to provide feedbacks and request clarifications. Based on the task execution status and feedbacks, HQ can decide to initiate to step (1) again for re-planning. \\


\subsection{Interfaces}
This section describes the three game interfaces used by players, which are the mobile responder interface for field responders, the task assignment interface and the situational awareness interface for HQ players.\\

Compared to the on-the-loop version of AtomicOrchid, the mobile interface is largely unchanged except for the HQ task tab (Figure \ref{fig:study3mobileInterface}). The task tab now displays a task with text description and map visualisation of the task at the top. The bottom half of the interface is a message box showing task-specific information from HQ. It should be noted that the HQ can still send broadcast information (visible to everyone), which will be displayed in the chat tab. \\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study3/system/mobileInterface}
  \caption{Mobile interface in study 2}
  \label{fig:study3mobileInterface}
\end{figure}

The situational awareness interface is the same as the HQ interface used in study 2 (Section \ref{sec:studytwointerface}). It provides information about game status monitoring, and a broadcast message channel for communicating with field players(Figure \ref{fig:study3SAinterface}).\\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study3/system/HQ2Interface}
  \caption{Situational awareness interface operated by HQ2}
  \label{fig:study3SAinterface}
\end{figure}

The task assignment interface is created to support In-the-loop interaction with Agent. As an overview, the interface has a map on the left. The figure \ref{fig:study3TAinterface} is a screenshot of task assignment interface. Components are numbered in the figure to illustrate functionalities of the interface. Player/target locations and assignments are presented on the map. At right side of the interface is a task assignment panel. The left (1) column of the panel shows pending assignments while right column (2) shows existing task status. Figure  \ref{fig:study3TAinterface} (5) shows an example of a proposed task assignment: player MD and GO are assigned to target 07. Within each confirmed task assignment (6) a feedback indicator indicates the field player`s response to this assignments (no response, reject, accept).\\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study3/system/HQ1Interface}
  \caption{Interfaces in study 3}
  \label{fig:study3TAinterface}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{img/study3/system/editmode}
  \caption{Edit mode of task allocation interface}
  \label{fig:study3editmode}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/study3/system/msgmode}
  \caption{Pop up messaging panel}
  \label{fig:study3msgmode}
\end{figure}


\begin{itemize}
\item Plan request button: \\
This button triggers agent re-planning (Figure \ref{fig:study3TAinterface} (3)). The agent will calculate an optimized plan based on task status, and present it to the HQ on the pending panel. This button allows HQ to decide when to initiate a re-plan. \\

\item Plan keeping checkbox:\\
These checkboxes are attached to every task assignments in the confirmed panel (Figure \ref{fig:study3TAinterface} (6)). If the checkbox is ticked, the planner will keep the corresponding assignment in the next re-planning. In other words, the planner will keep the assignment fixed, performing partial planning for the rest of the team. 

\item Plan edit panel: \\
Manual plan edits will be activated by clicking the `edit' button (Figure \ref{fig:study3TAinterface} (4)). The assignments in pending area will change to edit mode. Assignment can be created, modified and deleted through drag and drop interaction (Figure \ref{fig:study3editmode}). \\

\item Plan approval button: \\
This button approves all pending assignments (Figure \ref{fig:study3TAinterface} (7)). All pending assignments will move to the confirmed area. Alternatively, assignments can be approved individually by clicking individual confirm button on the pending assignment when the edit mode is activated. \\

\item Text messaging panel:\\
The messaging panel (Figure \ref{fig:study3msgmode}) can be toggled by clicking msg button on the confirmed assignments (Figure \ref{fig:study3TAinterface} (4)). The panel is supposed to be used for assignment-specific information. Therefore, the messages in this panel are only visible to the two involved players and HQ.\\

\item The Feedback indicator:\\
The feedback indicators are attached to the right hand side of the confirmed assignments (Figure  \ref{fig:study3TAinterface} (6)). The field players can easily provide feedback on their assignment through the mobile responder interface (introduced later). There are three possible values for the indicator (no response, reject, accept). Because rejections typically indicate issues that needs to be followed up by HQ, the rejection will be highlighted with red. \\

When both involved players both accept the assignment, the keep checkbox will be ticked automatically. This is a mechanism to avoid accidental interruption of the accepted assignments in subsequent re-plans. \\

\item Stop button: \\
The stop button can be used to indicate an emergency termination of an assignment (Figure\ref{fig:study3TAinterface} (6)). If this button is clicked, the assignment will be dismissed both in the mobile and HQ interface. \\
\end{itemize}

%more images


\subsection{The planning agent}\label{sec:studytwoagent}

One big change to the planner compared to study 2 is the addition of a partial planning feature. The agent can take a list of fixed assignment as input. It then plan for the players and targets that are not involved in the fixed assignment list. This functionality has two potential uses: \\

\begin{enumerate}
	\item It allows human operators to contribute part of a plan and ask the agent optimize the rest.\\
	\item It allows human operators to annotate some on-going tasks, so that they could not be changed in dynamic re-planning. \\
\end{enumerate}

Apart from the partial planning feature, the input/output of agent is not changed.\\

%insert a summary picture.\\

\section{Study Design}
Participants were recruited through posters and emails. A total of 20 participants were recruited. 10 participated in session A and 10 in session B (Appendix \ref{app:demo3}). All participants were reimbursed with 15 pounds for 1.5 hours of study. For each game session, there are 2 HQ players and 8 field players. The majority of participants were students of the local university. The HQ players were recruited from researchers in the computer science department. \\

Because the HQ interface is a lot more complicated then that of the study 1 and study 2, we add an extra 0.5 hour training session before the formal study for HQ players to get familiar with the new task assignment interface. We anticipated that the workload of operating the human in-the-loop interface would be a lot more than that of operating the on-the-loop interface. Therefore, there are two HQ payers recruited in each session to split work in the control room. One of the two HQ player operates the new task allocation interface (described in section \ref{sec:study3system}), while the other player operates the situational awareness interface (described in study 2, section \ref{sec:studytwointerface}) to assist the other HQ player by providing situation awareness and sending broadcasting information. \\

Upon arrival in the HQ (set up in a meeting room at the local university), participants were briefed and asked to consent to participate. Roles were randomly assigned to field players (firefighter, medic, transporter, soldier). Field responders were provided with a smartphone; HQ coordinators with a laptop. Game rules and interfaces were introduced, and participants were assisted in setting up their phones and laptop clients. Field responders and HQ coordinators were given 5 minutes to discuss a common game strategy. All field responders were accompanied to the starting point within the designated game area, about 1 minute walk from headquarters.\\

Before the formal session begins, there was a training session for field players to get familiar with the mobile interface. The training session has a very simple game setting with only four targets nearby the starting point. The training session ends when field responders collect all four targets nearby. Once field responders were ready to start formal session, one researcher started the game engine, triggering a ``game start'' message to be sent to the mobile interfaces. Gameplay commenced for 30 minutes. A ``Game over'' message by HQ concluded the game. Field responders returned to HQ for the post-game session.\\

The game area was the same as for study 1 and 2, on the local university campus (Appendix \ref{app:area3}), 400 by 400 meters, without heavy traffic. The terrain of the game area includes grassland, a lake, buildings, roads, and footpaths and lawns. There are two drop off zones. Due to extra HQ training sessions and improved interface, the number of targets is increased to 20 (from 16 in study 2) to the increase game challenge.  There were four targets for each of the four target types. The pattern of cloud movement and expansion was the same for both game sessions and the same as for study 1 and 2.\\

We recorded both system logs and video of interaction in the field for analysis. To capture the distributed, concurrent nature of the interaction, four researchers with camcorders shadowed the field player teams, and one researcher recorded the action in the HQ. The replay tool was used to synchronise and analyse triangulated game events, player positions, and concurrent video recordings  (Appendix \ref{app:vis3}).\\

Our interest in this chapter is how socio-technical interaction is organised around the computational planning support, hence our focus is on the control room first, but then we trace information flow and decision making into the field. In practice, video recordings of the control room were catalogued to identify key decision points in teaming and task allocation, which served to index sequences (episodes) of interest (Section \ref{sec:aprIA}). Interesting distinct units of interaction were then transcribed and triangulated with log files and field video for deeper analysis; the results of which we present in this chapter.\\


\section{Data Analysis}
This section starts with overview of game results, messaging system usage and task assignments, as they served to index episodes of interest. Selected episodes of game play are then presented in order to unpack the interactions surrounding the task assignment activities in the control room. We provide these episodes as vivid exhibits of how members accountably organise their team coordination in situ \citep{Crabtree2012}. The order in which we present the episodes follows the common practice of moving from exhibits of typical/unproblematic instances, via more complex/difficult in- stances, to exhibits that display problematic interaction or even complete breakdowns (\citep{Heath2010}).\\

Overall, 28 of the 40 targets were evacuated in two sessions (16 in Session A and 12 in Session B). The player`s health status in session 1 is better  (Avg 90, Sd 9.3 ) then that in session 2 (Avg 48, Sd 41). Two deaths occurred at the begging of session 2. More details of death will be presented as episodes later in this section. \\

\begin{table}[h]
\centering
\footnotesize
\label{my-label}
\begin{tabular}{c|cccccc}
          & Target saved & Health max & Health min & Health avg & Health Sd & Death \\ \hline
Session A & 16           & 99         & 75         & 90.75      & 9.337     & 0     \\
Session B & 12           & 97         & 0          & 48.12      & 41        & 2    
\end{tabular}
\caption{Result overview of study 3}
\label{tab:ResultsOverview}
\end{table}

\subsection{Messaging system}
One change of the messaging system made for this iteration is separating channels for assignment-specific and broadcast messages. The HQ1, with the task assignment interface, is responsible for sending message in assignment-specific channel, while the HQ2, with the situation awareness interface, is responsible for sending messages in the general message channel. This section will reveal how this design plays out in the field trials. \\


\begin{table}[h]
\centering
\footnotesize
\begin{tabular}{c|ccc}
Session 1               & Sent by HQ & Sent by FR & Total \\ \hline
Broadcasting msg        & 35         & 3          & 38    \\
Assignment specific msg & 22         & 15         & 37    \\
Total                   & 57         & 18         & 75    \\
Session 2               & Sent by HQ & Sent by FR & Total \\ \hline
Broadcasting msg        & 31         & 13         & 44    \\
Assignment specific msg & 19         & 11         & 30    \\
Total                   & 50         & 24         & 74   
\end{tabular}
\caption{Task assignment overview}
\label{tab:ResultsOverview}
\end{table}

We found HQ  players frequently send messages to update FRs about the locations of the radiation cloud, (e.g. ``Radiation Status- 38  39  37 and Drop Point 7 all out of bounds'' ) and provide navigational guidance (e.g. ``go north  and west around the water''). HQ is also observed to send messages to repeat and enhance the task assignment (e.g. ``turn to 49'').\\

On the other side of the message channel, field responders send messages to request tasks (e.g. ``please advise'') and cloud status (e.g. ``Which way is it moving?''). Field responders also occasionally send acknowledgments to HQ`s messages (e.g. ``Copy that.''). \\

Most messages in the general message channel are general information about the clouds. However, we also found 11 messages in the general message channel (out of 82) are clearly addressed to individual teams. The specific player initials are mentioned in those messages. (E.g. ``NG and YI approach quicker to 41 drop off to 8'')\\

\subsection{Overview of task assignments}
In the following tree diagrams, plans are broken down into individual task assignments. Each individual assignment may go through 4 stages in the planning process (creation, approval, feedback, and execution). The assignment status for each stage is summarized in the following diagrams(Figure \ref{fig:TaskAsSession1},\ref{fig:TaskAsSession2} ). \\

\begin{figure}[ht]
 \includegraphics[width=1\textwidth]{img/study3/TaskAsSession1}
\caption{Task assignment in session 1}
\label{fig:TaskAsSession1}
\end{figure}

\begin{figure}[ht]
 \includegraphics[width=1\textwidth]{img/study3/TaskAsSession2}
\caption{Task assignment in session 2}
\label{fig:TaskAsSession2}
\end{figure}

In summary, HQ and the planning agent contribute to the task planning activities in the control room. The planning agent created a total of 45 task assignments with an additional 5 assignments created manually by HQ. HQ approved a total of 39 assignments. Field responders accepted most of the approved assignments (30 out of 39). 9 assignments were rejected or not responded to. During task execution, occasional HQ interventions resulted in 5 task cancellations and 5 assignments being override. In the end, players managed to evacuate a total of 28 (out of 40) targets in 2 sessions.\\ 

Although the diagrams (figure \ref{fig:TaskAsSession1}, \ref{fig:TaskAsSession2}) suggest a sequential planning-execution process (creation -> approval -> feedback -> execution), we actually found that various planning activities (e.g. assignment creation, approval, intervention, communication) are highly intertwined in the control room setting. In the rest of the section, episodes of game play will be used to unpack the interactions surrounding the task assignment activities in the control room. The episodes in later sections will be presented with a standard orthographic notation detailed in section \ref{sec:aprIA}.\\

\subsection{Confirming the plan}
As summarised above, a majority of task assignments are generated by the planning agent and approved by the HQ players. The episode 3.1 demonstrates a typical case of the routine task planning process in control room. \\

\noindent\texttt{\textbf{Episode 3.1}
\emph{Context: HQ paid attention to a team (MV XW) who was carrying target 43 back to drop off zone 7.}\\
\textbf{16:45, HQ2:} XW and MV.\\
\textbf{16:50, HQ1:} (taking) 43. \\
\textbf{16:51, HQ2:} They should be going to drop off (zone) 7 and get 36 (Figure \ref{fig:study1ep311}) \\
\textbf{16:58, HQ1:} why don`t they go this way?\\
\textbf{16:49, HQ2:} tell them to go 36 afterwards.\\
\textbf{17:04, HQ1:} ok this one (refer to target 36). Do you tell them? (Figure \ref{fig:study1ep312})\\
\textbf{17:05, HQ2:} Should I tell them? (Typing)\\
\textbf{17:07, HQ1:} Yeah, go for 36. Maybe After the drop off, I think then (will) get confused.\\
\textbf{17:13, HQ2:} I will tell them to go after drop off.\\
\textbf{17:14, HQ1:} Yeah, Yeah. \\
\textbf{18.10,} (The team dropped off target 43)\\
\textbf{18:22, HQ1:} (click re-plan) \\
\textbf{18:26,} (new assignments, the team is assigned to MV,XW -> 36)\\
\textbf{18.28, HQ1} 36, yes (Click confirm)\\
}

\begin{figure}[ht]
\centering
\begin{minipage}[b]{0.45\linewidth}
\includegraphics[width=1\textwidth]{img/study3/ep11}
\caption{ep 3.1, HQ1 (left) HQ2 (right) }
\label{fig:study1ep311}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
 \includegraphics[width=1\textwidth]{img/study3/ep12}
\caption{ep 3.2, HQ1 (left) HQ2 (right)}
\label{fig:study1ep312}
\end{minipage}
\end{figure}

At the beginning of this episode, the team MV, XW are carrying a target (43), approaching drop off zone. At [16:45], the HQ2 noticed the team was going complete its current task and began to consider a new target for them [16.51]. HQ2 proposes that 36 should be prioritized (Figure \ref{fig:study1ep311}). HQ1 agreed with the suggestion and decided to send the assignment after the team completes existing task (Figure \ref{fig:study1ep312}) [17:07]. At 18:10, the team dropped off target. After the drop-off, the HQ requested a re-plan. The agent assigns the team MV, XW to target 36, which is consistent with decision of the HQ players. At the end, HQ approved the assignment [18:28]. In this typical case of task assignment, HQ  can be seen to be monitoring the task execution, and making timely requests for new task assignments. HQ`s discussion suggested that the agent task assignment was approved after a careful review of player, target and radiation status. In addition, much of HQ1 and HQ2`s discussion happens before the team drops off the target; this kind of forward planning was observed on several occasions.\\

\subsection{Just Following the Plan}\label{sec:study3planfollow}
Episode 3.2 gives a more problematic example of accepting the planning agent`s task assignments. Episode 3.2-1 describes the interaction in the control room; while episode 3.2-2 gives the perspective of the field players.\\

\noindent\texttt{\textbf{08:32, Episode 3.2-1}\\
\emph{NG and YI have just completed a task together; DI is some distance away.}\\
\textbf{08:32,} (HQ1 request assignment for Idle player NG, YI))\\
\textbf{08:37,} (New assignment NG, YI -> 50) \\
\textbf{08:40,} (HQ1 confirmed plan) \\
\textbf{09:09,} (HQ1 request assignment for DI who has just become idle) \\
\emph{(NG have not confirmed the previous assignment; DI is closer to target 50)}\\
\textbf{09:16,} (New assignment arrived NG, DI -> 50 )\\
\textbf{09:17,} (HQ1 confirm NG, DI -> 50)\\
}



In this episode, the HQ1 requests assignment twice for idle players, which is a routine activity for HQ1 (As discussed in episode 1). Firstly, HQ1 request and approve new assignment for NG, YI [08:32]. 30 seconds later, DI become idle [09:09], so HQ1 request plan again. Because DI is closer to target 50 and NG YI have not accepted their assignment, the agent replaces DI with NG in the new assignment to minimize travelling distance of field players. Although HQ1 does not verbalize his reasoning process the quick approval suggests HQ1 may not have inspected the new assignment carefully and may not have noticed that the previous assignment will be overridden, potentially interrupting a task in progress. The episode 3.2-2 picks up the activity of NG and YI as the first new task assignment is approved by HQ.\\

\noindent\texttt{\textbf{Episode 3.2-2}\\
\emph{NG YI received a task update after they finished their previous task}\\
\emph{(Team NG YI received new task NG, YI -> 50)}\\
\textbf{08:39, NG: } Task changed, to what? \\
\textbf{08.43, NG: } Oh sh*t, there is a radiation zone sh*t. \\
\textbf{08:53, NG: } It (target 50) is close to the lake. It is triumph road we have to go that way. \\
\textbf{08:55, YI: } Yea, we need to. No this is the lake. \\
\textbf{09:00, NG: } Oh that is the river, so it is that way, Can we go? Yes we can go, this road?\\
\textbf{09:10, YI: } Yes it should be. \\
\emph{(Their task is interrupted by new assignment YI, DI -> 50)}
\textbf{09:18, YI: } Task changed.\\
\textbf{09:19, NG: } Task changed? What? \\
\textbf{09:23, YI: } No, it is the same.  \\
\textbf{09:26, NG: } I do not see anything. \\
\textbf{09:28, YI: } You are DI, right?\\
\textbf{09:29, NG: } No.\\
\textbf{09:30, YI: } En? You are no DI? DI, wait. \\
\textbf{09:37, NG: } I can not see my Task.\\
\textbf{09:45, YI: } You are NG, Oh no, I need DI.  \\
\textbf{09:48, NG: } You should go back then. Or send a message, Oh I can not see my task.\\
\textbf{10:02, NG: } I think the page is not loading.\\
}
 
NG and YI have already received the task to rescue target 50 but have not accepted or rejected it. While they are discussing how to reach the target the second task assignment arrives [09:10], the agent requires YI to team up with the remote player DI to pursue the same target, 50. The team is confused after the change of task. YI thinks that the task did not change because the target is still 50 [09:23] (YI: ``No, it is the same.''), and NG thought the interface is no longer working [10:02](NG: ``I think the page is not loading.''). After YI confirms NG`s initials, she realized she needs to switch teammate (to DI). \\

Overall, the task interrupt is resulted in a problematic sense making process in the field. Meanwhile the players in the control room appear unaware that anything untoward has occurred. The observation also reveals that several factors could have led to the task interruption including the absence of response from field responders; computational planning performed by agent without timely field feedback; and HQ`s failure to discover the task interruption during assignment approval. 

%This episode can be an example showing that computationally `optimized' assignment is not socially optimized for teams and HQ supervision failed to tackle the issue.\\

\subsection{Correcting the plan}
HQ players occasionally chose to change the task assign- ments generated by the planning agent; episode 3.3 presents one such example.\\

\noindent\texttt{\textbf{Episode 3.3}\\
\emph{CE and KH are currently assigned target 03 but have not accepted; other players are free}
\textbf{04:18,} (HQ1 click request plan)\\
\emph{(Assignments arrived: CE KH -> 06, MP GO ->07, MB ,WB -> 10)}\\
\textbf{04:24, HQ1:}  What? Why I am getting? Ahh, one of these guys does not accept. (Figure \ref{fig:study3ep31}) \\
\emph{(Referring to the team of CE, KH.)}\\
\textbf{04:29,} (HQ1 clicked keep on assignment CE KH -> 03) \\
\textbf{04:33,} (HQ1 request re-plan)\\
\textbf{04:40,} (Assignment arrived: MB, WB -> 10, MP, GO -> 07)\\
\textbf{04:42,} (HQ1 click confirm)\\
\textbf{04:56,} (MP, GO accepted)\\
}

\begin{figure}[ht]
\centering
\begin{minipage}[b]{0.45\linewidth}
\includegraphics[width=1\textwidth]{img/study3/ep31}


\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
 \includegraphics[width=1\textwidth]{img/study3/ep32}
\end{minipage}
\label{fig:study3ep31}
\caption{ep 3.3, HQ identifies a task interruption, highlighted on right figure}
\end{figure}

After HQ requests a new plan, the agent proposes a set of assignments, one of which (CE KH -> 06) interrupts the existing task of a team (CE KH -> 03). HQ1 queries this change (``What? Why I am getting?'') realises that they have not explicitly accepted the previous task [04:24]. It should be noted that this kind of task interruption only happens when field players did not accept the tasks (Section \ref{sec:study3system}), making the agent think they are idle at that moment. After finding this problem, HQ then requires the agent to ``keep'' existing assignment [04:29] and requests a new plan from the agent, which is then approved. In contrast to episode 3.2, HQ1 notices and compensates for the field players` failure to explicitly accept the task, and the field players are able to continue with the previously allocated task without interruption.\\
\subsection{Changing the plan}
At the start of session B there is an extreme example of the HQ players overriding the planning agent. \\

\noindent\texttt{\textbf{Episode 3.4}\\
\emph{Context: At start of the session 1, all players were idle waiting for initial plan.}\\
\textbf{01:25,} (HQ1 requested initial plan)\\
\textbf{01:28,} (4 initial assignments arrived)  \\
\textbf{01:29, HQ1:}  why, it is stupid. \\
\textbf{01:33,} (HQ1 click edit)\\
\textbf{01:53, HQ1:} I want this one (HQ1 drag targets to replace agent planning) this one and this one.\\
\emph{HQ1 replaced 3 out of 4 targets in the task assignment. The three prioritized targets very are close to the original cloud}\\
\textbf{02:03,} (HQ1 clicked confirm) \\
\textbf{02:07, (HQ1 talk to HQ2) HQ1:} I think we should get the far ones first. \\
}

The episode begins with HQ requesting initial task assignments for the whole team. When the agent gives HQ  a set task assignments for approval, HQ complained about it [01:29, HQ: why, it is stupid.], indicating he is not satisfied with the plan. HQ then click edit button to switch to edit mode. Under the edit mode, HQ dragged 3 targets to replace the targets in agent assignments. The three prioritized targets are the ones that are closet to the radiation cloud. After HQ confirmed his modification [02:03], he said to HQ2 that the far away targets should be rescued first [02:07]. The execution result of this heavily edited plan is not ideal. Among the 3 three modified assignments, 1 of them is finished successfully, 1 assignment is cancelled later, and 1 assignment leads to player ``death''.\\

\subsection{Coping with the unexpected}
Episode 3.5 picks up shortly after episode 3.4, and exemplifies how HQ adapts task assignments to changing task status. \\

\noindent\texttt{\textbf{Episoe 3.5}
\emph{Context: after plans are confirmed in episode 3.4, HQs are monitoring FR's progress}\\
\textbf{02:09, HQ2:} they cannot walk there straight. (Figure \ref{fig:study3ep51})\\
\emph{Referring to team MB, GO, HQ2 point out that the straight path to one of the target is blocked by radiation}\\
\textbf{02:14, HQ1:} So who is that. (Target) 04 (HQ1 open the message panel) \\
\textbf{02:20, (HQ 1 Types message)}  You are heading to an area affected by cloud, You need to be very fast. [Fig 6] \\
\textbf{02:45, HQ2:} 04 is now in the cloud. \\
\textbf{02:45, HQ2:} Oh god, that is so fast.\\
\textbf{03:20, (HQ1 Types message)} Stay to the lake as possible!\\
\textbf{03:33, HQ1:} Shall we cancel (assignment 04) that or shall we wait for report? (HQ1 opens msg panel to talk to MP GO)\\
\textbf{03:43,} (HQ1 opens msg panel to talk to MP GO) \\
\textbf{03:50, HQ2:} I think (Target) 04 is only an animal, screw the animal.  \\
\textbf{03:52, (HQ1 Types message)} Abort, target compromised, proceed to target 07. \\
\textbf{04:06, } (HQ1 sent message)\\
\textbf{04:11, } (HQ1 click stop on the assignment of MB, GO->04)\\
}

\begin{figure}[ht] \label{fig:study3ep52}
\centering
\begin{minipage}[b]{0.45\linewidth}
\includegraphics[width=1\textwidth]{img/study3/ep51}
\caption{ep 3.5, HQ2 points to a team}
\label{fig:study3ep51}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
 \includegraphics[width=1\textwidth]{img/study3/ep52}
\caption{ep 3.5, HQ sends msg for task cancellation}
\label{fig:study1ep52}
\end{minipage}
\end{figure}

After confirming assignments in episode 3.1, the HQ2 points out that one assignment may now be impractical because the route to target has already been blocked by a radiation cloud [02:09] (Figure \ref{fig:study3ep51}). HQ1 immediately opens message panel to send warnings and urge the team to move quickly (Figure \ref{fig:study3ep52}). However the cloud expansion seems to be faster then HQ originally expected [02:51]. Apart from sending route guidance to the team, HQ1 starts to consider cancellation of the assignment. After HQ2 agree with the cancellation, HQ1 sends a message to the team to inform them that the assignment is going to be cancelled and instructs them to go to new target 07. The assignment is formally cancelled in [04:11]. After HQ1 cancels the task, he starts to request new assignments from planner and allocates target 07 to the team later. In this case the HQ players realise the risk and are able to abort the task and redirect these field players out of danger.\\

\subsection{When it all Breaks Down} \label{sec:playerDeath}
In episode 3.4, in which the HQ modified 3 agent assignments. In the modified plan, the team CE, KM is instructed to go for a target very close to a radiation cloud. We look first at the HQ perspective (episode 3.6-1), and then at the field players` perspective (episode 3.6-2).\\

\noindent\texttt{\textbf{Episode 3.6-1}\\
\emph{(Context: One team (CE, KM) is end up heading to radiation cloud.)}\\
\textbf{4:52, HQ2 } They (CE KM) are walking right into their death. \\
\emph{(CE and KM were heading to target 03 which is now at opposite side of a radiation cloud)}\\
\textbf{5:14, (HQ messaging) } Careful, you are approaching the cloud. Move extremely fast to the cloud. Go around the lake to return.\\
\textbf{5:32, HQ: } God, too slow.\\
\emph{(The team CE KM is completely in the mid of radiation)}\\
\textbf{5.46, (HQ typing message) } Move closer to the lake.\\
\textbf{5:50, } (The team went through the cloud, their health is below 20, the target 03 is now at the edge of the cloud)\\
\textbf{6.39, HQ2: } What are they trying to pick up?\\
\textbf{6:43, HQ1: } The fuel.\\
\textbf{6.48, HQ2: } I am not sure whether they can survive picking up the fuel. No, now is more concern of surviving. \\
\textbf{7:05, (HQ messaging) } Abort 03, return top to (target) 99. \\
\textbf{9.04, } (HQ1 stopped task of CE KM) \\
\textbf{9.05-10:08, } (HQ requested re-plan 4 times, no new plan available for CE KM) \\
\textbf{9.50, HQ1: } No targets for them? There are lots of them. \\
(Team CE, KM stay in the cloud all the time, and finally dead)\\
}

At the beginning of the task, the radiation cloud is already between target and the field team CE and KM. The cloud is expanding quickly, which catches the HQ1 by surprise. As a result, 2 messages are sent by HQ1 to guide the team to avoid the cloud [05:14,5:46]. However the team is still excessively exposed to the radiation when they reach the side of the target, so HQ1 decides to abort the task [07:05]. After HQ1 cancels the assignment, the team is still exposed to radiation. HQ1 then tries to assign the players to other targets by requesting the agent for new assignments [09:05-10:08]. However, the agent does not assign the team to any task because the team`s health is too low. HQ1 seems to be confused about why the agent refused to assign targets. He repeatedly requests plans three times and says ``No targets for them? There are lots of them (refer to targets).''[9:50]. During this process, the team are still standing in the cloud. They finally lose all their health points and become incapacitated. Field players` perspective is given below. \\


\noindent\texttt{\textbf{Episode 3.6-2}\\
\emph{CE and KM are heading towards target 03}\\
\textbf{05:15, CE: } (Reading out the message) You are approaching the cloud, move extremely fast to the cloud, Ok! \\
\textbf{05:21,} (CE grabbed KM and started running) (Figure \ref{fig:ep361})\\
\textbf{06:12,} (The team CW, KM ran all the way across the cloud) \\
\emph{(After ran through the cloud, they are checking the health value.)}\\
\textbf{07:02, CE: } how dead are you?\\
\textbf{07:04, KM: } Pretty much dead.\\
\textbf{07:06, CE: } I am pretty dead as well.\\
\emph{(The team is trying to locate the target, but it is unsuccessful) (Figure \ref{fig:ep362})}\\
\textbf{07:28, CE: } Do you know what is funny? We have to get back.\\
\textbf{08:24, CE: } It should be somewhere around here! We are getting close.\\
\emph{(Assignment cancelled)}\\
\textbf{08:52, CE: } there is a new task, No task at the moment? \\
\textbf{[...]} 
\emph{(After assignment was cancelled, the team was still trying to locate the target)}\\
\textbf{09:44, CE: } I am pretty much dead and radiation is 12. Where is it! It says it is on this street but it is not. \\
\textbf{10:06, CE: } Oh I am dead.\\
}

\begin{figure}[h]
\centering

\includegraphics[width=0.7\textwidth]{img/study3/ep361}
\caption{ep 3.6, CE (left) grabs KM (right), start running into cloud. }
\label{fig:ep361}
\end{figure}

\begin{figure}[h]
\centering
 \includegraphics[width=0.7\textwidth]{img/study3/ep362}
\caption{ep 3.6, CE (left) grabs KM (right) walks around, looking into mobile screen, trying to locate target}
\label{fig:ep362}

\end{figure}

The part 2 begins with player CE reading the HQ message (``You are approaching the cloud, move extremely fast''). After this message, CE grabs teammate KM and starts to run through the cloud \ref{fig:ep361}.  After they run through the cloud, the team check their remaining health value [07:02] and start searching for the target at the edge of the radiation cloud. About half a minute later, the assignment is cancelled by HQ [08.52] and no further task is allocated (as seen above). Although the task has been cancelled, the HQ does not to assign a new task to the team [3.6-1, 9:50]. The field players note but then appear to ignore HQ1`s instruction to abort [08:24] and continue to search for the target. The field players seem to interpret the lack of a new task as license to remain where they are and are eventually overwhelmed by the radiation.\\

\subsection{Missing feedback from field}
Lack of feedback leads to false assumptions by the agent (i.e. players are still available), which in turn compromises its optimization (e.g. section \ref{sec:study3planfollow}). We found that HQ may also be distracted by the lack of response, in that they have to guess a player`s intention without their feedback. \\

\noindent\texttt{\textbf{Episode 3.7}\\
\emph{(New assignment MV XW -> 36, XW accepted, MV had no response)}\\
\textbf{13:05: HQ1: } I think they have not received any task probably . \\
\textbf{13:22, HQ1: } Just do not have response, I do not know why.  \\
\textbf{13.32, HQ2: } MV and XW, I suppose they go to 36. \\
\textbf{13:35, HQ: } They are moving, but they did not accept that. \\
\textbf{13:48, } (HQ click request, new assignment to MV XW -> 43, NO response from MV XW)?\\
\textbf{13:51, HQ2: } I am not sure they are still going south; I think they (MV XW) are going to 43 instead. \\
\textbf{13:59, HQ1: } HQ: they are going to 43.\\
\textbf{14:05, HQ1: } HQ: they just do not have any response, no reply. But they are coming for it, they are coming. \\
}

In this episode, the team MV, XW was assigned target twice [12:30,13:48], but the team neither rejects nor accepts those two assignments. The HQs are observed to guess intentions of the field responders 3 times [see 13:32, 13:51,13:59] and complain about the non-response twice [see 13:22, 13:48]

\subsection{Division of labour in HQ}

In session 1, the responsibility for HQ1 and HQ2 to send messages are not fixed as originally designed, but dynamically negotiated between the two HQ operators. The following fragment is a typical case of negotiation.\\

\noindent\texttt{\textbf{Episode 3.8 }
\textbf{17:04, HQ1: } Ok this one (refer to target 36). Do you tell them? \\
\textbf{17:05, HQ2: } Should I tell them? \\
\textbf{17:07, HQ1: } Yeah, (tell them to) go for 36. \\
\textbf{(HQ2 sent message) } MV and XW  move north of the water and go round to 36\\
}

In this fragment, HQ1 asks HQ2 to send a message to instruct a team to go for a target 36. The message is a task-specific, but it is sent by HQ2 through the broadcasting message channel.\\

In session B, we do not find similar negotiation. However, in the post game discussion, the HQ2 expressed the view that he had too little to do (other then sending general messages), while HQ1 had too much to do:\\

``The interface I use was completely useless, became I can only message everyone at the same time, basically spamming everybody, so the only thing that I can do is, Oh , the cloud moves there and there. At the same time, HQ1 had to message to everybody privately. While he was doing that, he couldn`t do new plans. So there is a lot stuff for him be I coundn`t do anything.''\\

\section{Discussion}\label{sec:study3discussion}

In previous section, episodes were presented to illustrate how the In-the-loop interaction design plays out in the field.  The episodes reveal that, to a large extent, the HQ players are successfully involved in the control loop. However, we also found some confusions and misunderstandings occur between agent and the human which lead to issues and implications for interaction design.  \\

\subsection{How does the In-the-loop design play out?}
The interface functionalities are designed to enable HQ to engage in a range of interface interactions such as plan requesting, editing, approval and cancellation. This section examines how these functionalities are utilized and to what extent they help HQ to stay in the control loop. In what follows, we firstly examine the usage of individual interface functionalities. Combining the episodes presented in the previous section, we then reveal how the division of labour plays out with the support of these interface functionalities.  \\

\begin{enumerate}
\item \textbf{ Plan request and approval.} The plan request function is used by HQ to trigger agent re-planning. The design of the plan approval stage gives HQ an opportunity moment to review and influence the final plans before they are sent to field responders. Both functions are essential for the human and agent to collectively produce task assignments, constituting the routine task planning work in the control room. The two functions are the two most frequently used interface functionalities (HQ requested plans for 45 times; approved 39 task assignments). Deciding the appropriate moment to request plans and approve desired assignments requires HQ to closely monitor the task status. The uses of the two interface functionalities are usually observed together with discussion of task execution status, which indicates that HQ players are engaged in the planning-execution loop with a supervisory role. \\

\item \textbf{ Plan edits.} The ``plan edits'' enable HQs to directly intervene in the planning. We observed HQ modify undesirable agent plans twice throughout the field study (Episode 3.3, 3.4). It should be noted that the function is designed to be used infrequently, because the planning agent is supposed to take over the majority of the computational intensive planning activities. \\

\item \textbf{ Plan cancellation.} Further, the task cancellation functionality allows HQ to influence task execution after plan approval. In episode 3.5, we observed an assignment being cancelled and teams being reassigned due to unexpected cloud activities. This may suggest that the combination of cancellation and re-planning can be a useful tool for HQ to respond to contingencies in the task execution.\\

\item \textbf{ Partial planning } The partial planning functionality allows HQs to indirectly influence the planner. For example in episode 3.3, HQ identified a task interruption in the proposed plan. He then required the agent to keep an existing assignment and perform re-planning again.  This episode can be seen as a case in which HQ is able to make sense of the task status and utilize the partial planning functionality to influence the assumptions of the planner agent. \\

\end{enumerate}

Apart from the above mentioned functionalities to support HQ intervention, the task assignment interface appears in many cases to provide an effective shared representation of the current state of the game. As well as showing current player and target locations and player health it also makes visible the currently approved task allocations, field player responses and any new plan that has been requested or is being edited. This shared information forms the common ground between the HQ players and the planning agent.\\

HQ players are observed to closely monitor this view and its representation of plan execution. For example episodes 3.1, 3.2, 3.3, 3.5 and 3.6 all reveal HQ players` awareness of field player progress and current tasks, episodes 3.5 and 3.6 show awareness of the cloud`s location in relation to players, and episodes 3.1, 3.3 and 3.4 show HQ players engaging actively with proposed (rather than current) task assignments. We observe that the HQ players are quite capable of modifying the agent`s plans when they wish to, for better (episode 3.3) or worse (episode 3.4). HQ is also able to intervene in current task allocations, which is successful in resolving the situation in episode 3.5 (but not in episode 3.6).\\

%The usage of individual interface functionalities indicates the interface functionalities may actually serve its design purpose, which is to support the HQ requesting, editing, approving and cancelling the plans. In what follows, we will examine how the division of labour play out as a result of the interface support. the observation reveals that HQ players contribute to the planning with a set of supervisory activities, while the agent take over computational optimization of task allocation. \\

%1) Firstly, HQ players are observed to closely monitor the plan execution. For example in Ep 1, field players` task progress is mentioned by the HQs. In episode 3, HQs expressed their concerns about cloud and player locations, while in episode 6, HQ`s are more concerned with the uncertainty of field players` intention. The task \\

%2) Occasionally, HQs also need to modify plans when agent proposed plan is not desirable. For instance in Ep 2, HQ overridden 3 our of 4 agent proposed assignments to implement his own strategy. Further, HQ`s intervention is also required when contingency rises from task execution. For example, The HQ terminated an approved assignment due to unexpected cloud activities. A re-plan is quickly followed up to assign new assignments to the affected teams.\\ 

%3) The forward planning activities are occasionally observed. For example, HQ`s discussion of future plans for a team is observed in Episode 1. The forward planning activity is thought to be not well supported by the system and it is unclear whether this activity contributes to the planning. More details will be discussed in section x. 

On the other hand, the agent is found to take over the computationally complicated task optimization, freeing up the HQ to play their supervisory roles. Throughout the two sessions, the HQ requested the planner to re-plan 49 times. The agent generated 45 task assignments, 34 out of which are approved by Headquarters. In comparison with the agent planner, the human only created 5 task assignments. The fact that agent creates a large proportion of assignments suggests the agent successfully takes over the routine planning to a large extent. \\

In many cases the communication between HQ and the field players is unproblematic, and most targets are successfully evacuated according to plan. This situation seems to be considerably better than that reported in chapter \ref{ch:studyone} and chapter \ref{ch:studytwo}, and we conjecture that this is due at least in part to differences in the mobile interface in the trials reported here. Specifically, unlike in the studies reported there, the current task allocation is shown as a graphical overlay on the mobile map, not just as a textual instruction (given by the HQ player in chapter \ref{ch:studyone} or the planning agent in chapter \ref{ch:studytwo}). This seems to significantly reduce the field players` confusion about their current target and team- mate and where to find them. The seemingly better situation of task communication is consistent with the requirements (Section \ref{sec:study3system}) outlined for interface improvement that stressed the importance of structured, domain-specific task representation for both HQ and field responders.  \\

A pattern division of labour is also observed between the two HQ players in the control room. To recap, the two HQ players in control room are split into two roles. The role of HQ1 is to handle task assignments and send assignment-specific messages to field responders. The role of HQ2 is to support monitor task status and send general chat messages. To support them, the messaging system  is split in to two channels, general information and assignment-specific (Section \ref{sec:study3system}). The messaging interfaces allow each HQ player to take control of one of the messaging channel. Participants were briefed on the designed role division in training session before the game play. However, the system does not play out exactly as designed in the field studies. 11 messages in the general message channel are task specific, which indicate the HQ players may occasionally violate the designed division of responsibility. Specifically, we have seen in session 2 the HQ players accepted this division of capabilities but were frustreated by it. However in session 1 the HQ players developed their own work-arounds for this based on verbal negotiation, so that at times HQ2 would use the general broadcast interface to send task-specific messages for HQ1, relying on the identification of the intended field players by their codes within those messages.


\subsection{Responsibility and Complacency}\label{sec:huilimperfection}
In the game probe, the planning can be seen as partially automated by the planner agent. The task optimization performed by the agent can be considered to be `imperfect` because it fails to consider any organizational efforts/overhead required execute the plans and plan changes, that is, the social cost of implementing plans. The result of this imperfection has been illustrated in previous study (Chapter \ref{ch:studytwo}), and also in episode 3.2 and 3.3. In the episodes 3.2 and 3.3, the agent proposes new plans that will disrupt ongoing activities, albeit because the respective field players have not (yet) explicitly signalled their acceptance of these tasks.\\

This imperfections can be thought of an ``natural'' for agent planning support, as computationally ``optimized'' assignments from the planner may not be socially optimized for the responder teams (Section \ref{sec:study2social}). This highlights the importance of human involvement in the planning activities. In principle, the human in-the-loop interaction design allows the human, in this case the HQ players, to take active responsibility for system. For example, in episode 3.3 we see HQ1 successfully `correcting' the plan to allow for missing information (responses) from the field players. However in episode 3.2 the HQ player failed to prevent the unnecessary task interruption in the approval stage, resulting in extra coordination work and sense making for field responders. Considering this case in more detail we see that it arose from the combination of: lack of field player feedback; failure of HQ monitoring; and the particular computational optimization performed by agent (which assumes that there can be no overhead if a task has not been formally accepted).\\

The failure case in the episode is similar to the well-observed phenomena discovered by automation researchers called complacency \citep{Kaber1997}. The complacency phenomenon refers to the human failure to detect occasional automation failures. Studies of automation suggests that complacency can be classified as an attention-based monitoring failure, which is likely to happen when human is engaged in multi tasking. In the case of episode 3.2, the quick approval of problematic assignments suggests that the plan is not properly reviewed. The HQ`s attention could be a factor of the monitoring failure. As the HQ player is trying to allocate tasks for idle players, they may exclusively focus on the new assignments for the idle players rather then other potentially conflicting assignments.  If the interface failed to attract HQ`s attention to the conflict, HQ may approve the plan as long as idle players are properly assigned. Although the failed in episode 3.2, the interface highlight does grab the attention of the HQ in episode 3.3. Some studies shows that complacency is found in both naive and expert participants and cannot be overcome with simple practice \citep{Parasuraman2010}. Therefore other mechanisms to counter the complacency effect may be needed, such as a richer involvement of the human in the planning, which we pick up further in Section \ref{sec:study3supportPlanning}.\\

\subsection{Tacit confusions}
While many interactions were essentially unproblematic we do observe a number of areas where silent, missing or invisible information led to confusion and break down.\\

For field players, task cancellation is presented on a notification (``task changed'') followed by a blank task page with only the text ``No task assigned at the moment''. The field study suggests that the presentation could be problematic for the field players. Firstly, being assigned with no task does not successfully convey the meaning of task cancellation (i.e. ``Don`t carry on''). The episode 3.6-2 shows a case in which the players completely ignores the task cancellation and carry on doing and a risky task. In episode 3.2-2, the player NG even thinks that the blank task interface implies a malfunction of the mobile interface. Even if the players understand task cancellation, its implications can vary. Without a task, the players can chose to, for example, (1) stand by doing nothing, (2) find targets by themselves, (3) escape for their lives. Therefore, the field players may be confused about what to do next. In another example (not presented) of cancellation, the field players were stuck in a radiation cloud when their task was cancelled. With a high radiation reading and loss of a target, they don`t know what to do next so they send messages to HQ for clarification. They finally leave the radiation cloud after they receive and accept new assignments from HQ. This example shows the implicit instruction of ``Don`t carry on'' is confusing. Instead, the explicit instructions, which directly point out what to do next may be desirable. For example, in the case of AtomicOrchid, frequent instructions might be ``stand by'', ``go back'' or ``escape''. We therefore argue that the interface should encourage HQ consider such ``explicit'' instructions and support quickly sending such instructions. \\

Second, episode 3.4 in which the HQ player drastically modifies the agent`s proposed plan illustrates vividly that the current interface makes the agent`s proposed plan available to the HQ player, but does not reveal the agent`s priorities or reasoning. The HQ player enacts a policy of evacuating the targets nearest to the radiation cloud first, presumably in the belief that the planning agent has (a) used a different priority and/or (b) not given due consideration to evacuating those targets. In fact the planning agent will have considered and rejected those targets, based on its model of field player movement, radiation cloud spread and `permitted' radiation exposure (none). None of the agent`s models are likely to be perfect but at present they are not open to inspection. It soon transpires (episodes 3.5 and 3.6) that the HQ player`s initial expectation of how quickly the radiation cloud will spread is very wrong. In an ideal world we would want this information to be available to the HQ players, so that the common ground can be expanded to include not only the plan but the reasoning behind the plan. However, as in the previous point, there is also the challenge that we may overwhelm the HQ player with information in a time-critical decision-making situation.\\
	 
Apart from the issues of task cancellation, issues of field player feedback also emerged. The field observations showed that the feedback system is crucial for both the agent and HQ players to keep track of the task status. Overall, most of the assigments (30 out of 39)  have been responded to by the field players. However, there are still a number of un-responded-to assignments that causes issues in coordination. For the agent planner, the lack of field response may lead to false assumption of the availability of the players, which in turn, compromises the subsequent re-planning (Episode 3.2 and 3.3). For the HQ players, the lack of field response adds to the uncertainties in the task status as well. HQ players have to take efforts to guess the intentions (Episode 3.7). We might wish that the field players would always respond in a timely manner. However there may be good reasons why they have not or cannot at present, e.g. if they are incapacitated or there are temporary problems with communication. Also, in the scenario of AtomicOrchid, no matter how fast the responders accept assignments agent planning may happen concurrently.\\

One strategy is to treat the lack of response as an uncertainty in the task execution, and it might be better for the system and agent to view this lack of information more positively and concretely as a `known unknown'. For example, the planning agent might create a plan (or multiple plans) that take into account the possibility that these assignments may transpire to have been accepted or rejected (at least in the player`s thoughts). Similarly, the interface might make visible the uncertainty, and perhaps also highlight the other information which could be impacted as a result, such as contingent plans. \\

Interactive system researchers have outlined a list of strategies to tackle the inevitable uncertainties, one of which is to reveal the uncertainties to operators so that they can make informed decisions \citep{Benford2006,Skeels2008}. One straightforward approach for visualizing uncertainties is to highlight the affected data and various methods for highlighting have been proposed in literature \citep{Conti2006}. However, in a real-time control scenario like AtomicOrchid, the highlighting approach has to be applied with caution.  The operators have limited resources (attention, limited time and cognitive workload capacity) to tackle various issues in a multi-threading, time constrained task setting. Abuse of interface highlighting may contend for the limited attentional resources. There are evidences that visualization of uncertainties is likely to overload decision makers in time limited decision-making, which in turn, degrades their ability to respond in a timely manner \citep{Zuk2007}. Take episode 3.5 as example, although the system highlighted potential task interruptions as a result of lack of response, the operator still ignored it. \\

In episode 3.6, the HQ  become confused when the planner stops giving assignments. In this case, the HQ requests plans four times and complains about the lack of response from the planner. However, the planner does not produce more assignments simply because the idle players have too little health to take any more assignments. This policy and reasoning of the planning agent is not visible to the HQ player (although in this case the reasoning leads to not doing something, which may have its own representational challenges). \\

\subsection{Support human planning} \label{sec:study3supportPlanning}
%positive bit
As seen in all episodes, HQ players are observed to utilise the task interface to assess current game status, while in episodes 3.3, 3.4, 3.5 and 3.6 we have also seen how they can modify the agent`s plans. This suggests that the interface is sufficient in providing basic situational awareness for HQ players to make their own plans. The drag-and-drop based plan editing interface also enforces various constraints on task assignment so that all plans are at least valid, i.e. well-formed. For example, each player and each target can be assigned to at most one task, and each task can only have players with the correct combinations of game roles for the target. The interface also highlights players and targets on the map when they are manipulated so that the HQ player can readily assess location and proximity when editing task assignments. In the view of situated action \citep{Suchman1987}, the plan for the team is itself a projective representation of actions. What the system achieved here is to enhance the representation on the interface level and open an opportunity for human teams to sketch on the representation with situational awareness support. However, the observations also reveal some potential for improving support for human planning.\\

Returning to episode 3.4, the HQ player massively revises the plan. The modified plan turned out to be undesirable as it leads to 2 assignment cancellations and 2 player deaths (Episode 3.6).  We observe that the planning agent is silent with regard to the problems in the player`s proposed plan. As the planner has ruled out the risky plan in the first place, the reasoning behind the original plan may be important information that should have been exposed to HQ to inform their decisions. While making visible the planning agent`s reasoning might have discouraged the player from changing the plan so dramatically, there will still surely be situations in which plans could or should be changed. And in this case the player is currently left to ``do their best''; in short, the current system will make plans for a person to change or approve, but will not help that person to plan beyond ensuring that their plan is well-formed. If, rather, the planning agent were to simulate (and perhaps extend) the proposed modified plan then it could provide the HQ player with at least one view of the possible outworking of their plan.\\

In the current system the agent performs forward planning, i.e. it considers what field players might do in the future, not just in the current/next task assignments. However this in- formation is also not made available to the HQ players. In episode 3.1 we also saw one of several examples of the HQ players also planning for future task assignments. However they had no way to record this or feed it into the system; they simply had to make a note or remember what they were thinking when the current task was completed and they had the chance to check and intervene. For at least some situations it might offer benefits if the agent`s future plans could also be viewed, and if the HQ players also had some way to support their own future thinking.\\

However, again we are considering attempting to visualise and interact with significantly more data and more complex data which is liable to further complicate the interface. For example, for the agent to share information about its reasoning behind a particular task assignment, it may need to present its prediction of the future game state and its assessment of current game status. It may well be problematic for the HQ to digest this extra information in a time-constrained task environment. Various studies have identified the problem of information overload in system interaction design in the \ac{DR} domain \citep{Carver2007,Turoff2004a}. The problem occurs when information is presented at a rate too fast for a person to process \citep{Hiltz1985}, and it may lead to a list of human performance consequence \citep{Hiltz1985} including failure/inaccurate response,  systematically ignoring input, and input recoding (to more compact form). \\

%\begin{enumerate}
%\item Fail to respond to certain inputs,
%\item Respond less accurately than they would otherwise,
%\item Respond incorrectly,
%\item Store inputs and then respond to them as time permitted,
%\item Systematically ignore (i.e., filter) some features of the input,
%\item Recode the inputs in a more compact or effective form, or quit (in extreme cases).
%\end{enumerate}

Various techniques have been explored to alleviate the problem on information overload in different application domains such as security monitoring \citep{Conti2006}, teleoperation \citep{Kadous2006}, and communication systems \citep{Hiltz1985}. However, the specific research of information overload for task allocation support in \ac{DR} domain is still rare. There is a danger that the extra forward planning support may introduce the risk of overloading human operators. Therefore, more studies are required to evaluate the trade-off between its benefits and consequences for human performance.\\



% \subsection{Unsupported forward planning activities} merge
%The agent performs n-step [need to confirm] looking ahead planning (see section of agent algorithm) for each re-plan. Similar to the agent, HQ players are observed to engage in forward planning activities. For example, in Ep 1, the HQ anticipated a team was going to finish assignment soon and plan to assign a new target for them. Later, HQ triggered a re-plan and the result was consistent with the HQ`s previous plan. In some other cases, the result of agent re-planning was not consistent with HQ`s plan. Therefore, HQ has to make decisions about whether to follow the agent or not. As both HQ players and the agent conducted forward planning, sharing of relevant information may help HQ to understand the agent`s reasoning and make informed decisions.  Again, excessive and ineffective explanation of agent plans may introduce the danger of overloading the HQ players.  [Connecting to information overload]




%7.* Smoothing the workflow\\

%8.* Accountability become opaque by using the agent. \\

%[a separate reading list available for this chapter]\\

\section{Lessons from interaction design} 
Herein, we offer a brief summary of the lessons learnt from this third study that may benefit the designers of planning support systems, in particular, in relation to situation awareness, human error, and interacting with computational planning. These may be particularly relevant for settings in which timely human decision-making is critical. We furthermore also set our lessons into context with related work.

\subsection{Common ground}
Common ground is a critical requirement to making collaborative decisions in an effective and timely manner. Through our field trials, we have identified the following features as constitutive to common ground through providing a mutual situation awareness for the participating parties (HQ, field responders, and the agent).
\begin{itemize}
\item \textbf{Shared representation}. The task interface enabled common ground between HQ players and the planning agent -- the basis for enabling HQ players to read, modify, and confirm the agent's task assignments. Shared representation was also critical to align field players and HQ view of the environment, e.g., through the messaging channel.  
\item \textbf{Awareness of current state}. Episodes evidenced HQ displayed awareness of task progress, threats, and field responders' locations and proximity as critical in their planning.  
\item \textbf{Domain-specific task representation}. Providing a consistent representation that made use of domain-specific visual cues was an important feature to enable alignment and consistency across views and between mobile (field) and stationary (HQ) representations. 
\item \textbf{Awareness of future actions}. HQ engaged with \textit{proposed} tasks -- reading proposals in conjunction with awareness of current state, modifying, and confirming was seen to be an essential aspect of the situated planning work. 
\end{itemize}

Our recommendations also align with the theoretical framework model of situation awareness proposed by \cite{Endsley2001}, which argues the SA needs to be supported by three levels including 1) Perception of the elements in the environment 2) Comprehension of the current situation and 3) Projection of future status.\\ 

\subsection{Supporting Mixed-Initiative Planning} 
Some interactional challenges have become evident in the field trial that can be attributed to the interaction with the computational agent.\\
\begin{itemize}
\item  \textbf{Constraining task assignments} was seen as a clear advantage of the planning support in this setting, to guarantee only well-formed task assignments.
\item \textbf{Making reasoning visible}. Modifications of plans as a result of which responders were sent in harm's way may have been avoided if the grounds upon which the agent computed task allocations had been available for inspection. The challenge is how to implement this without inundating the operator with information.
\item \textbf{Feedback on modifications}. As a further step to making visible, the agent could also provide feedback on human modifications of its task assignments, e.g., in terms of safety and risk.
\item \textbf{Forward planning} of the agent could be made visible on demand to enable planning ahead. 
\end{itemize}

Our recommendations echo seminal work on human considerations in context-aware systems, which provided principles to support intelligibility and accountability \citep{Bellotti2001}; similarly we stress that the goal for planning support systems should be  to be accountable for their actions, therefore, `what they know, how they know it, and what they are doing about it' [ibid., p. 201] needs to be legible by the operator. Furthermore, as planning is oriented towards the future, yet produced as a contingent, situated activity \citep{Suchman1987}, the interface needs to support revision and revoking of plans in situ, and furthermore provide the situational awareness essential to do so.  

\subsection{Interactional trouble}
We have encountered the following interactional challenges that likely generalise more broadly to related settings.
\begin{itemize}

\item \textbf{Complacency} describes the phenomenon whereby occasional failures of automation may be difficult to detect \citep{Kaber1997}. Particularly, when the operator has learnt to trust the computational component. Mechanisms to counter this may turn towards more human involvement in the planning, however, there will be a fine line so as not to create information overload. 
\item \textbf{Non-responsiveness} has been observed to create uncertain situations. It is important to realise this could equally be caused by technical communication outages, as well as by human non-response. Designers may attempt to incorporate this as  `known unknowns' in the system, for example planning could be done with an estimated \textit{probability} of a positive response. 
\end{itemize}   

The wealth of computational approaches to the problem of `planning under uncertainty' \citep{Chang2007} suggests uncertainty is a key recurring problem, particularly in time critical settings. In this context, it may also be important to look towards interface design guidelines to complement computational approaches in order to avoid or minimise human error at the interface level \citep{Norman2013}.


\section{Professional feedbacks}\label{sec:RGworkshopone} 

This section will present the results of a workshop we conducted with a professional disaster response charity called \acf{RG} (Section \ref{sec:rg}). The purpose of this workshop was to get professional feedbacks about the AtomicOrchid(AO) platform to understand the realism of the disaster simulation based on AO. Based on the feedback, we reflect on the strength, limitations and potential improvements of AO platform. \\

The workshop was centred on a demonstration of the HAC-ER system for \acf{AO} (Section \ref{sec:lraisupport}). The AO is a component of the HAC-ER demo system. Others components include information crowdsourcing, multi-UAV control interface for DR, and DR operation provenance store (Section \ref{sec:lraisupport}). Each component was allocated one session (about 45 mins). The AO session was structured as follows:\\

\begin{enumerate}
	\item A presentation introducing the AO platform and HQ interface.
	\item A hands-on session for RG members to operate the HQ interface. For the purpose of the demo, the field players in AO were simulated.
	\item A discussion of the AO platform for Rescue Global to reflect on some themes including: Command and Control structure, Division of Labour/Task and team planning.
\end{enumerate} 

We also encouraged free discussion throughout the AO session, which led to some emerging themes including: data connection, time-scale of planning in real DR operations and other interface improvement suggestions.  

\subsection{The Rescue Global feedbacks}
Based the feedback from the \ac{RG}, the \ac{AO} setting  mirrors some aspects of \ac{RG}`s disaster operations. Firstly, the \ac{RG} member quickly recognise the task-team matching mechanism is very similar to aspects of resource-needs matching in their operation. At the beginning of the introduction presentation of \ac{AO}, one of the responder commented: \\

\begin{quotation}
``This is actually very similar to what we do when we do reconnaissance now. We identify needs, and we are aware of what the resources that we have and match it into what resources we have and match the needs into resources.''\\
\end{quotation}

Further, the team formation mechanism could also be mapped to aspects of their operations by \ac{RG} members. \ac{RG} confirmed that members from different organisations and with different skills often teamed together for tasks. However, cross-organisation at teaming activities are mostly done in an informal way, as one \ac{RG} member described: \\

\begin{quotation}
``What we did in Philippine is that , say we found school, and we talked to the MSF medics \footnote{Medecins sans frontieres, rescue charity, http://www.msf.org.uk/ } we have bumped into. They have medics, can run some clinics there. Then they need some security, they are comfortable with Simon and Bren (two path finder in \ac{RG}), we can help them out, we did that, but almost informal way'' \\
\end{quotation}

The statements of \ac{RG} indicates that their collaboration with the MFS medic teams are based on an informal  relationship with them and the formal organisational collaboration is often missing. \ac{RG} also stressed that the paradigm of cross-organisation team formation in \ac{AO} is desirable, but difficult to achieve in a formal way. They highlighted that the major challenge for realising the \ac{AO} paradigm is organisational. As the one \ac{RG} member stated:\\

\begin{quotation}
``The challenge with that is that UN clustering system, make separation of different tasks, they then delegate the tasks down to say Health cluster, and UNISAF, all the way to little agencies, they won't work with anyone else, because they do not know them, they do not have relationship, so UN structure stops that... does not mean you can not change it, but current paradigm would not allow it ''
\end{quotation}

Based on \ac{RG}'s feedback, we also identify some unrealistic aspects of the \ac{AO} setting. Firstly, \ac{RG} member expressed concerns related to data connection. They highlighted that the activity in \ac{AO} requires good connections between field and HQ, which is not always the case in a disaster situation. Given that, \ac{RG} members can still imagine a version of \ac{AO} being used in situations with poor data connection. They suggested that the information in the field can be collected and input into the planning support system in a slow and manual way (e.g. through a satellite phone call). In that situation, they still think planning support aspects of \ac{AO} would be useful to them, though the pace of planning and information collection would be much slower and manual. \\
\begin{quotation}
``say  OK, there is not live link between HQ and field responder, could you have that, in the field people can start sending reports, which could be done like satllete phone, then HQ can load on to this (AO), come up with suggestions, because can not task directly to the field , there is another call,  it puts in lots of gaps and pauses, but still be able to have the system giving suggestions based on manual input, which do not require broadband. ''
\end{quotation}


In terms of \acf{C2} structure, RG frequently refer to two frameworks of \ac{C2},  the Bronze, Silver, Gold model (Section \ref{sec:lrstructure}) and the National Incident Command Framework (\citep{Command2008}). The assumption of Command structure in \ac{AO} seems to be detached from both NICF and \ac{BSG} in that both NICF and \ac{BSG} have several hierarchical command levels (Bronze, Silver, Gold) and ways to sectorise units (geographical, functional).  In the \ac{AO} setting, both the command hierarchy and unit sectorisation are missing. At the interface level, the information presented to each command level may need to be tailored to their specific paradigms (operational, tactical, strategic):

\begin{quotation}
``For operation, we would like have interface with 2-3 levels of sophistication, that takes you into different paradigm. For example, you do not what simple transactional barrier for your section commander,...  you do not section commander know that. Simple data (at the bronze level), enhanced data (at sliver level), at gold, stripping away all details. ''
\end{quotation}

From feedback, we also noticed that the time-scale of \ac{RG}'s operation is much longer then \ac{AO}. As one \ac{RG} member described how tasks are allocated in a multi-agency operations: 

\begin{quotation}
``The amount of work we do here , is probably a month of work from what we saw in Philippine, like 15-20 job orders, and that take about a month.... The problem is how they are all disconnected, you got tightly coupled system with lots of moving part, with massive gap between each one, so say example, that cluster of systems, you have that in .... , that in ..., that in another, they then meet once a week, can be once a week and then get information, dissamincate and give out jobs, it is just unbelievably slow.''
\end{quotation}

Although the time-scale of \ac{AO} is unrealistic for \ac{RG}'s typical activities,  they think that \ac{AO} can be seen as an ideal, speeded-up version of mulit-agency operation, because it automates lots of manual process in terms of information capture and presentation and promotes commonly recognised information picture across agencies:

\begin{quotation}
``What is good about this, it is getting towards automating and visually representing what we manually constructing, with posts, white broad and flip charts. It is not because what we are crap, it because everyone in the world does that ...  That is why commonly recognised information picture is so important, you essentially got, here is what happen, here is our resource, then you can make decision.''
\end{quotation}

Apart from information capture and presentation, the \ac{RG} team also saw the value in \ac{AO} as a tool to balance work between field the HQ: 

\begin{quotation}
``I think it (\ac{AO}) could be useful that you can use to help people in the field to gather information, file it back and forget it, which is really helpful, because otherwise what we have to do is we do the plan do the resource allocation in the field which is really time-consuming, if we say field get information and send it back, HQ receive and plan based on them.''
\end{quotation}

The statement indicates that planning of resource allocation does happen in the field and it is desirable to transfer the workload to HQ. The statement also identifies \ac{AO} as a (potential) tool to balance division of labour. \\


\subsection{Conclusion and Reflection}
In the previous section, we have reflected on both realistic and unrealistic aspects of the \ac{AO} game based on feedback from the \ac{RG} workshop. The resource target mapping and teaming aspects of \ac{AO} setting are found to be similar to activities in \ac{DR} operations, though the teaming in DR operations is likely to be conducted in an informal way. On the other hand, both the time scale and command structure in the \ac{AO} do not match what currently happens in \ac{RG}`s\ac{DR} operations. The time scale of \ac{RG}`s operation is much longer then \ac{AO}; The Command and Control framework in \ac{RG}`s \ac{DR} work has hierarchical levels and sectorisation for some levels, both of which are missing from \ac{AO}. Further, the assumption of good data connections in the field are also found unrealistic. However the \ac{RG} team thought that the core planning support aspects of \ac{AO} would still be useful even when data connection is poor. \\

Although \ac{AO} was not built as a tool to support real disaster operation (it is designed to be a simulation game), the \ac{RG} team still found some aspects of \ac{AO} demonstrates elements of a future planning support system that would be desirable to them. Firstly, \ac{AO} portrayed a picture of automated information capture and visualisation which is appreciated by \ac{RG}. Secondly, \ac{RG} also appreciate that the division of labour facilitated by \ac{AO}, in which the HQ (with the planning agent) handles the task planning while the field responders just need to ``gather information, file it back, and forget it''\\

Elsewhere in this discussion (Section \ref{sec:study3discussion}) we have touched on several areas where more information might in principle be shared between the planning agent and the HQ players, such as agent priorities and reasoning, uncertainty and future plans. We note that would almost certainly make the interfaces and visualisations more complex and increase the risk of information overload. However, if the system were operating at the kind of pace that Rescue Global use to characterise their own activities then there would be a lot more time to work with than in the current version of \ac{AO}. So a challenge for future work is to understand more about the interactional challenges of this kind of time-constrained but relatively slow-paced situation.\\

\section{Summary}
The objective of this field study here was to explore the design issues surrounding an In-the-loop interaction pattern. The exploration was conducted through field trial of an \acf{AO} probe with In-the-loop support, with particular focus in the planning activities in control room. The Game probe is evolved from the On-the-loop version of \ac{AO} that was trialled in study 2. To realise a human in-the-loop interaction, the \ac{AO} system allows the human HQ to approve, edit and cancel the agent generated plans. \\

Findings from interaction analysis of field observations, triangulated with log files, reveal how the In-the-loop interactions played out. Our observations indicate that the human coordinator and the automated planning support can successfully work together in most cases. Supported by a task assignment interface, human coordinators take active responsibility in the system by inspecting and `correcting' the agent proposed plans. However, occasional failures of planning are also observed due to a number of issues including 1) complacency 2) silent, missing or invisible information 3) and limited system support for human planning. Several of these observations suggest additions to the information to be conveyed by the interface, but at the risk of information overload for the people in the HQ.\\

Based on the findings, we also summarised a list of lessons for the In-the-loop interaction design. Firstly, the importance of common ground for human agent coordination is highlighted and we suggest that common ground should be supported by domain-specific information models, appropriate visual representations of the models, and articulation of future actions. Secondly, several interface features are highlighted to support mixed reality interactions, including 
constrained task assignments, visible plan reasoning, feedback on task modifications and forward planning support. Third, our observations reveal several interactional troubles including complacency and non-responsiveness that need careful consideration.\\

%Findings from interaction analysis of field observations, triangulated with log files, reveal how the In-the-loop interactions played out. By examining the usages of interface functionalities and presenting episodes of task planning, we argue that a pattern of division of labour is achieved, in which HQ players contribute to the planning with supervisory activities and interventions, while the agent takes over computational optimization of task allocation [ref of interaction design]. Meanwhile, a set of interactional issues around In-the-loop design also emerged. \\

%Firstly, the human supervision may not be the perfect solution for the imperfection agents. We found human HQ players sometimes quickly approve assignments without consideration of task interruptions caused by agent planning [ref ]. The HQ players also override (safer) agent plans to implement risky plans, which lead to player `death'. Therefore, we argue that stronger human  involvement may come with undesirable human performance consequence (e.g. complacency, uninformed decisions). \\

%Secondly, some of the observed undesirable human performance may arguably be a result of insufficient information sharing between human and agent. However, we also argue that the excessive information sharing may complicate interface and interactions between human and agent, which in turn, leads to information overload. Therefore, the trade-off may need to be carefully considered for interaction design. Further, forward planning  activities are frequently observed and they are not well supported by the agent. One option to support the activity is to make the agent reveal some information regarding to future planning (e.g. prediction of future game status).\\

%Finally, the lack of acknowledges and ineffectiveness of task cancellation have been identified as communication issues between field and the control room in section x. \\

%The discovered interactional issues lead to some design implications which are discussed with respect to two themes: Common ground, and Balance of responsibilities. Various issues of interaction highlighted the importance of Common Ground between human and agent. Through discussion of the observed interactional issues, we have identified some information that need to be shared for establishing the common ground. However, it is unknown how this information should be presented in a way that avoids information overload and, at the some time, contribute to the common ground.  \\

In addition, a workshop with a professional organisation has revealed strengths and weaknesses of the \ac{AO} simulation. In more detail, the resource target mapping and teaming aspects of \ac{AO} setting are found to be similar to activities in their \ac{DR} operations. However, the time-scale, command control structure and the assumption of data connectivities do not match their experience of current \ac{DR} operations. Although there are several unrealistic aspects of the \ac{AO} simulation, the member of the organisation still appreciate the core planning support aspects of the \ac{AO} system.\\

%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************

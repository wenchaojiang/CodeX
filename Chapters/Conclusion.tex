\chapter{Conclusion}\label{ch:conclusion}
To sum up, this PhD work uses a mixed reality game, AtomicOrchid, as a testbed to probe the design issues and implications for agent planning support system applied to disaster operations. Field trials were conducted for three versions of the AtomicOrchid game with different interaction design patterns (Figure \ref{fig:connections}). The first study was a non agent version of the game. The second and third studies probe two interaction design patterns, on-the-loop and in-the-loop). Video and system logs of the field trials are collected and interaction analysis is conducted to generate design requirements and interaction design implications. \\

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{img/conclusion/studies}
  \caption{Overview of studies}
  \label{fig:connections}
\end{figure}

The following sections summarise the contributions of the thesis, and conclude the thesis with limitations and an outlook on future work that this thesis might inspire.\\


\section{Summary of contributions}
Overall, the thesis has three key contributions to the interaction design of planning support for disaster response teams:\\

\begin{enumerate}
  \item[A] \textbf{The system prototypes.} The research produces real-world interactive prototypes (i.e. AtomicOrchid) for investigating human-system interaction in a disaster response settings. An iterative prototyping process is conducted throughout the three AtomicOrchid studies, which results in three interactive prototypes of planning support systems. On the one hand, the prototyping process is guided by the the interaction patterns generalized form \ac{LoA} models (\ref{sec:lrloa}). On the other hand, the system evolution is also inspired by key observations from iterative field trials. 
  
  \item[B] \textbf{The observations.} The field observation of the \ac{AO} trials generate thick descriptions of human system interaction in a \ac{DR} scenario. The key observations reveal both interactional issues and detailed system requirements which inspire system evolution across the three trials (Figure \ref{fig:connections}).
  
  \item[C] \textbf{The interactional issues and design implications.} For each study, field observations are further analysed to enrich our understanding of interactional issues surrounding automated planning support, and generate design implications which contribute to future development of automated planning support systems in the complex collaborative work setting of \ac{DR}. 
\end{enumerate}

The section \ref{sec:conclusionIE} gives details about the system evolution and the interface design rationale, followed by a summary of key observations in section \ref{sec:conclusionOB}. The interactional issues that emerged from field observations are detailed in section \ref{sec:conclusionIssue}. \\



\subsection{Interface evolutions}\label{sec:conclusionIE}
This section presents the interface evolutions of \acf{AO} across three field studies and the design rationales behind them.\\

The initial interface of AtomicOrchid (used in 1st study) is designed to provide basic coordination support by displaying game status and providing a broadcasting channel for communication. The control room is manned by 2-3 HQ players. Every HQ player uses a same interface which shows game status on a map. A chat box is provided to send and receive broadcast messages. A mobile interface is used by field responders. The responders share the same map with HQ, which displays game status with the exception of radioactive cloud. The messaging interface is placed in another tab. (Figure \ref{fig:study1interface})\\ 

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{img/conclusion/study1interface}
  \caption{Interface of study 1}
  \label{fig:study1interface}
\end{figure}



The 1st study discovered several flaws in the initial interface, which led to a number of design requirements. 

\begin{enumerate}
	 \item The interface should support quick acknowledgement and feedback in communication channel.
	 \item The interface should show freshness of messages in the communication channel.
	 \item The interface should provide support for geo-reference.
\end{enumerate}

The second prototype is designed to integrate a planning support agent with an On-the-loop design pattern (Section \ref{sec:patterns}), in which HQ only monitors task allocation and execution with infrequent intervention. A set of changes in the second version (used in study 2) of AtomicOrchid are partly inspired by the requirements from the study (Figure \ref{fig:study2interface}). In this version, all targets are identified by unique task IDs to support geo-referencing. Text messages in the broadcasting channel are labelled by time stamps to flag potentially outdated information. With the introduction of the planning agent, the interface also supports quick feedback to the agent with a single press. A new tab (``task'') in the mobile app also shows a text-based description of the agent task-assignment. In the HQ interface, the agent assignments can be revealed on request by the HQ players (HQ clicking on "show task" button).\\

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{img/conclusion/study2interface}
  \caption{Interface of study 2}
  \label{fig:study2interface}
\end{figure}

%purpose of the third study , lead to the interface. and requirements.
The results of the second study revealed that interface level support for HQ intervention is very limited in the on-the-loop version of AtomicOrchid. \\

This kind of intervention support is also essential for the in-the-loop study (the third). Therefore, a task assignment (Figure \ref{fig:study3interfacemobile}) interface is introduced for the third study to enhance the HQ's ability to intervene in the task planning. Task-specific communication channels are also introduced to avoid information overload in the broadcasting channel. Compared to previous HQ interfaces, the operations on the task assignment interface are a lot more complicated. Therefore, one HQ player is dedicated to operate this interface and another player is provided with the same HQ interface as the one in the on-the-loop version to provide situational awareness and handle broadcast messages. 

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{img/conclusion/study3interfaceHQ}
  \caption{HQ Interface of study 3}
  \label{fig:study3interfacehq}
\end{figure}

For the mobile interface, the tabs ``status'' and ``chat'' are kept unchanged from version 2 (renamed from ``map'' and ``messages''). The task interface is enhanced by a map-based presentation of the task assignment and the task-specific chat box is displayed below the assignment (Figure \ref{fig:study3interfacemobile}).

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{img/conclusion/study3interfaceMobile}
  \caption{Mobile Interface of study 3}
  \label{fig:study3interfacemobile}
\end{figure}


\subsection{Key observations}\label{sec:conclusionOB}
This section gives a brief overview of the key observations from the three studies. First, the non-agent AtomicOrchid trial (Study 1, chapter \ref{ch:studyone}) aims to give insight into how humans conduct planning (without agent support) in the time and spatially constrained disaster settings and to generate general requirements for a coordination support system which can be applicable to the next two agent-integrated versions of AtomicOrchid. The result of interaction analysis showed that team planning was dominated by local coordination between field players with in a ``situated'' manner. The field teams managed to organise their team and task allocations by utilising available resources such as local conversation, mobile interface, and remote messages. The HQ was observed to successfully provide awareness of the ``danger zone'' to the field teams through remote messages. However, HQ had little direct influences on the planning and actions of field teams. One potential reason could be the breakdown of communication between HQ and field responders. The communication breakdown is thought to be caused by a set of factors including communication modalities (text vs voice), training level of players and HQ and system interface designs.  \\

In study 2, a planning agent is integrated to the system with the human on-the-loop interaction design.  Through interaction analysis, we gain insight into the division of labour between human and agent (Section \ref{sec:studytwointroduction}) in which the agent takes over routine planning activities while the human focuses on other issues such as finding teammates, targets and choosing the best routes. However, there is also evidence showing the agent planning occasionally interrupts the workflow of the human team potentially because it fails to consider social cost of task changes. We also observed HQ player struggle to influence the plan because of the lack of interface level support. Further, a set of misconceptions in feedback loops are also observed (Section \ref{sec:studytwofeedback}).\\

In study 3, the system is evolved to facilitate In-the-loop interaction with the feedback from study 2. The main changes are a number of interface functionalities which enable HQ to approve, edit agent planning and monitor player feedbacks. Through observing the usage of this new functionalities in the control room, we observe an expected division of labour between in which:
% is it found or just desgin
	\begin{enumerate}
	 \item The HQ decide when to perform re-plan.
	 \item The HQ review every agent instruction for routine task planning.
	 \item The HQ deals with player feedback.
	 \item The Agent proposes task allocation.
	\end{enumerate}
	
Field observation show that division of labour is at least partially facilitated by the task assignment interface deployed in study 3 (Section \ref{sec:study3system}). The task assignment interface appears in many cases to provide an effective shared representation of the current state of the game. As well as showing current player and target locations and player health it also makes visible the currently approved task allocations, field player responses and any new plan that has been requested or is being edited. This shared information forms the common ground between the HQ players and the planning agent. HQ players are also observed to closely monitor this view and its representation of plan execution to gain awareness of cloud`s location in relation to players and current task progress. HQ players also engage actively with proposed (opposed to current) task assignments. HQ players are quite capable of modifying the agent`s plans when they wish to, for better (Episode 3.3) or worse (Episode 3.4).\\

Analysis of some failed cases of coordination also points out a number of interactional issues. The details of the issues, possible solutions and design implications are discussed in the following section \ref{sec:conclusionIssue}. \\


\subsection{Interactional issues and lessons}\label{sec:conclusionIssue}
There are a number of interactional issues that emerged from the field observations. This section reflects on interactional issues related to 4 themes including division of labour, common ground, accountability and support of situated actions.

\subsubsection{Division of labour}\label{sec:conclusionHH}
The On-the-loop and In-the-loop interaction designs have been trialled in two studies. To recap, the main distinction between the two interaction designs is the extent to which the human HQ is involved in routine task planning. For the on-the-loop design, the system is supposed to run without human input, while the in-the-loop system can not operate without constant human interaction. Guided by these two patterns, detailed system design has been implemented.\\

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{img/conclusion/huilvshuol}
  \caption{On-the-loop vs In-the-loop}
  \label{fig:huilvshuol}
\end{figure}

\begin{table}[]
\centering
\tiny
\begin{tabular}{lllll}
Division of labour &  &  &  &  \\ \hline
 & FR & \begin{tabular}[c]{@{}l@{}}1. Interpret instructions\\ 2. Organise team meet-ups\\ 3. Deals with navigational issues \\ (Locate target, find routs)\\ 4. Provide feedbacks (accept/reject)\end{tabular} & \begin{tabular}[c]{@{}l@{}}1. Interpret instructions\\ 2. Organise team meet-ups\\ 3. Deals with navigational issues\\ (Locate target, find routs)\\ 4. Provide feedbacks (accept/reject)\end{tabular} &  \\ \hline
 & HQ & \begin{tabular}[c]{@{}l@{}}1. Monitor and chose to intervene\\ 2. Sending other information in\\ broadcast channel\end{tabular} & \begin{tabular}[c]{@{}l@{}}1. Initiate re-plan\\ 2. Review every agent instruction\\ (Edit when necessary)\\ 3. Send information in \\ broadcast channel\\ 4. Deal with feedbacks \\ from field responders\end{tabular} &  \\ \hline
 & Agent & \begin{tabular}[c]{@{}l@{}}1. Send task allocations directly\\  to field responders\\ 2. Initiate re-plan\\ 3. Deal with rejections \\ from field responders\end{tabular} & \begin{tabular}[c]{@{}l@{}}1. Send task allocations to HQ \\ for approval\\ 2. Perform partial task planning \\ based on constrians specified by HQ\end{tabular} &  \\
Interface support &  &  &  &  \\ \hline
 &  & \begin{tabular}[c]{@{}l@{}}1. Representation of game status\\ 2. Broadcasting message channel\end{tabular} & \begin{tabular}[c]{@{}l@{}}1. Representation of game status\\ 2. Broadcasting message channel\\ 3. Task-specific message channel\\ 4. Field responder feedback highlighting\\ 5. Support for plan edits\\ (Drag and Drop interface)\end{tabular} & 
\end{tabular}
\caption{On-the-loop vs In-the-loop}
\label{tab:onin}
\end{table}


There are several performance differences between the In-the-loop and On-the-loop studies. Direct comparison of performance between In-the-loop and On-the-loop is not possible because the study 2 introduces a number of improved interface features (Table \ref{tab:onin}) that influence team performance as well. However, the difference of performance can still suggest some implications for interaction design.\\

\begin{enumerate}
\item \textbf{In-the-loop design is an option to reduce unnecessary task interruptions} \\
As we have summarised in section \ref{sec:huilimperfection}, there is evidence that the On-the-loop design is more likely to cause extra re-teaming and task interruption when compared to the In-the-loop design. In study 2, HQ has been observed to deliberately avoid unnecessary task interruptions and team reformations caused by agent planning. 

It can be argued that the difference is simply caused by a lack of reliability of the agent. Some AI researchers have attempted to enhance the reliability of the planning agent in handling social situations (Section \ref{sec:lrinterfaceagent}) with the approach of plan/intent recognition. For example, some may believe that a planning agent with better user/environmental modelling techniques can factor in the social process involved in task changes to inform plan generation. However, the work of \cite{Suchman1987} acknowledges the extreme difficulty of plan/intent recognition because of the weak logical inferential connections between a human's intent and actions in situ. Therefore, we believe that the in-the-loop design may be an useful approach to overcome the agent's limited reliability and utilise its capability at the same time.\\

However, the in-the-loop design may also have its own cost. On the one hand, it increases the workload of HQ player because they need to check each instruction proposed by agent. HQ players sometimes failed to recognise task interruptions even with interface highlighting support, which suggest that HQ cannot help to eliminate all the unnecessary interruptions. Effectiveness of the HQ may also depend on a balanced workload. In a multi-tasking control room environment, it is critical to balance the workload of the HQ players. Therefore, we need to carefully consider the trade-off between the increase of workload and the reduction of unnecessary task-interruptions \\

\item \textbf{HQ's ability to intervene in agent planning is required for both in-the-loop and on-the-loop design pattern.}\\
Compared to the in-the-loop study, the HQ players in the on-the-loop study are observed to struggle to intervene in the planning process, and we believe the performance differences are at least partially linked to the distinction between in-the-loop and on-the-loop. In on-the-loop study, the only way for HQ to intervene in the planning is to send unstructured text messages in the broadcast channel. HQ's ability to intervene has been greatly enhanced by a set of interface support introduced in the in-the-loop study. Some of the interface support is inspired by the implications from the on-the-loop study. It highlights the need for interface support for HQ intervention because both in-the-loop and on-the-loop appear to require HQ get involved when necessary. \\

\item \textbf{Human involvement may also incur system planning failure.} \\
Compared to the on-the-loop design, the In-the-loop design supports greater human involvement in plan generation. However, some planning failures appear to be directly linked to human involvement in the in-the-loop design. For example, there is a case of  human "death" occurred  when field players were trying to follow a human generated plan in the In-the-loop trial.  Although there are lots of factors contributing to the `death' case (e.g. insufficient training for field play, communication breakdown), the task assignment is thought to be too risky and not recommended by the agent in the first place. It is believed that the chance of human mistakes can be reduced by appropriate interaction design which helps to establish the `common ground' between the human and the agent. However, such a design would not be an easy task as it involves multiple design trade-offs  (Section \ref{sec:conclusionCG}).
\end{enumerate}

To sum up, task interruptions are more frequent with the On-the-loop design (compared to the in-the-loop study). This fact highlights the agents' inability to model the social process in human teams. Following the view of \cite{Suchman1987}, we believe that human's intentions and actions in situ are extremely hard to be modelled. Thus, the In-the-loop interaction design maybe  a much more feasible approach to overcome the limited reliability of the agent, however, the expense of higher HQ workload. Secondly, the interface support for HQ intervention has been proved to be important in both In-the-loop and On-the-loop settings. Finally, a human involvement in planning (in-the-loop) may incur some planning failures. This issue highlights the need for effective information sharing between human and agent, which helps to establish the `common ground' for coordination. \\


\subsubsection{Establishing common ground} \label{sec:conclusionCG}
The ``Common Ground'' (or as \cite{Suchman1987} suggested ``mutual intelligibility'') is the basis for human agent interaction \cite{Bradshaw2011}.  While, "common ground" may be improved with plan/intent recognition technologies (e.g. user modelling), this approach, if possible, can be extremely difficult (Section \ref{sec:sociotech}). The author believes that appropriate interaction design can enable human operators to understand and influence the planning agent. This section summaries the interaction design implications concerning the establishment of  ``Common Ground''.\\

In both study 2 and 3, the agent behaves like a "black box" which gives the results (task allocation). The interface only exposes the results of agent for HQ to monitoring. Through our observations in chapter \ref{ch:studytwo}, \ref{ch:studythree}, we find there could be some extra information shared between human and agent to improve planning.\\

The HQ players are observed (section \ref{sec:study3discussion}) to occasionally make some forward planning for field players. Because the forward planning is also performed by the agent to derive current plan, this information could be shared so that the HQ players can be provided with the agent suggestion when doing forward planning.\\

The reasoning behind current task allocations would also be usefully shared. In chapter \ref{ch:studythree} , HQ is found to override agent plans which sometimes lead to undesirable results. The HQ is also found to be confused when the agent stop assigning tasks to players with low health. Exposing internal reasoning of the agent may help the HQ to make informed decisions. \\

Misunderstanding between agent and human is also observed in the feedback loop in study \ref{ch:studytwo}. Firstly, human responders do not know how the agent is going to handle the rejection. They try to use rejection to revert to previous tasks, while the agent will give them more new instructions. Secondly, it is not apparent to field responders that their rejection will cause replanning for the whole team which can lead to costly task interruptions. Therefore, information indicating consequence of interface interactions should be also made available to human to facilitate accountability and ensure informed decisions. \\

Although we have identified a range of information which is missing for establishing "Common Ground", presenting this information could also be challenging. The information should be delivered in the right form (e.g text, visualisation, dialogs) and at the right time (e.g. pop up, on request?) \cite{Carver2007}. Especially in the multi-tasking, time-critical settings such as AtomicOrchid, multiple sources of information can compete for the attention of the human operator. Information overload could be a real danger of interaction design in this setting \cite{Lieberman2003}. Therefore, ways to expose the agent's internal information and its human performance consequence need to be further studied.   \\

\subsubsection{Faciliating accountability}\label{sec:conclusionAC}
The observations shows that both the spatial divide and the existence of planning support can be the factors that affect the natural accountability of member's activities. \\

In the 1st study, players heavily rely on local coordination for task planning. In a co-located setting, players can naturally make their actions observable and accountable to each other through conversations, body languages, gestures etc. In the distributed work setting, the spatial divide make accountability of member's activities opaque to each other. The technology support may need to play a role in supporting member's accountabilities. However, the reliance on local coordination indicates a lack of remote coordination support in the first version of \ac{AO} system. A set of functionalities including GPS/map sharing and broadcasting has been provided. We have observed players utilise the functionalities to make sense of other team members' actions (see section \ref{sec:s1localcoordination}) and act accordingly. However, coordination with remote players is still problematic, which can be evidenced by frustrations related to remote communication (Section \ref{sec:study1breakdown}). Therefore, we suggest remote coordination support should be built in a way that facilitates accountability across the distributed team by making player's activities observable and reportable.\\

In the second study, the issues of members' accountability are further complicated by the existence of planning support. Individual player's interactions with the planner agent (reject/accept plans) have impact on the planning of the whole team. However, while the rules of social conduct ensured accountability of action among co-located teammates, we found the impact of rejections on remote players was not properly appreciated; nor did the interaction design support making these individual human-agent interactions accountable to the whole team. We believe the interaction design should reveal the hidden cost of certain actions (e.g., rejections) help to make local decision making accountable to remote team members, ensuring consequences of local decisions for the welfare of all teams are understood. \\

\subsubsection{Supporting situated action}\label{sec:conclusionSituatedAction}
The thesis takes the view of situated actions proposed by \cite{Suchman1987}. The problem solving agent necessarily produces plans in an attempt to guide human teams, while easy  human acts in a situated manner. There is a need to design interactions that bridge the gap between the planning model of the agent and situated actions of the human. The observed human actions in the studies are well aligned with the the view of situated actions. In the non-agent version of \ac{AO} players are able to organise their activities with all their available resources (local conversations, messages, game status from mobile interface) without reaching a ``plan'' for the whole team.  In the second (on-the-loop) study, players are observed to utilise the agent plans as an extra resources for taking action in various social situations (Section \ref{sec:study2social}). Based on our observations, we summaries some recommendations for supporting the situated actions. \\

\begin{enumerate}
\item \textbf{Presenting agent plans as a resource for situated actions.} The agent ``plan'' itself is a representation of actions and their projective effects \cite{Suchman1987}. One key task of the system is to provide interface support for presenting the plans so that they can be easily utilised by people as a resource for deliberations on their actions. Through the three studies, we incrementally enhance plan representation. The final interface presents the agent plan in a structured way,  along side the the current task status (player feedbacks and existing plan under execution) and map-based location visualisation. This representation turns out to be effective for HQ players to make sense of the situation and act on the task allocation and monitoring.\\

\item \textbf{Facilitating the situated actions.} We observed that the human operators are faced with various social situations and contingent circumstance (Section \ref{sec:study2social}) in the field trials. The system may need to keep the flexibility to allow the human to proceed with their actions, no matter whether they choose to follow the agent plan or not. With the On-the-loop version of \ac{AO}, the agent plans sometimes ``get in the way'' as a hindrance rather then resources for players. The agent support system follow a strict planning model (plan-act-replan) without sufficient support for human involvement. Consequently, although the human can chose to ``disobey'' agent (by rejecting, or ignore), the result can be the complete abandonment of the use of the agent or even more problematic confusions (e.g. Episode 2.4 in Section \ref{sec:study2analysis}). On the other hand, the in-the-loop version of the interface provides flexibility for human action by providing interface functionalities for plan editing and the opportunity in the workflow for intervention. In this way, frequent human inputs are synthesized with the agent plan as a resource that support their situated actions. \\

\item \textbf{Supporting human-system mutual intelligibility.} By adopting the view of human agent interaction (Section \ref{sec:LRHAI}), the support system can be treated as an equal team player, with whom the mutual intelligibility should also be maintained to achieve concerted action \cite{Suchman1987}. Here we consider the Mutual Intelligent and Common Ground as interchangeable concepts.  Therefore we refer to section \ref{sec:conclusionCG} for suggestions on improving mutual intelligibility. \\
\end{enumerate}

%Mutual intelligibility is originally used to describe shared understanding in human teams, which is essential for concerted actions. In the context of AtomicOrchid, the existence of system should not hinder but support the achievement of mutual intelligibility among human team members. In the study 2 particularly , we found there is a danger to block natural human accountability in the human teams (Section x) as a result of failure to support  . 

\section{Limitations}
This section outlines some of the limitations of this PhD work. \\

By following a serious mixed reality game approach, the game AtomicOrchid is used to simulate some key factors of a distributed, time-critical task setting.  The fictitious game scenario can not completely mirror the setting of disaster operations. Firstly, the time-scale of planning is generally much longer in a rescue and reconnaissance mission (from hours up to days, Section \ref{sec:RGworkshopone}), while the AtomicOrchid has only a 30 minutes time-scale. Secondly, disaster response teams always prioritise critical tasks according to some specific code of conduct (e.g. tasks with human injuries may always be prioritised.). Therefore, the game objective of maximising targets saved may not match the real goal of a \ac{DR} team. According to professional feedbacks (Section \ref{sec:RGworkshopone}), the communication modality (text, rather then radio) and the assumption of `constant connectivity' are also not aligned with common real world environment. \\

Further, the seriousness of the simulation may also be a limitation of the game approach. Participants are frequently observed to laugh and make jokes about their health values (life), which indicates that they take the trials as a recreational experience. Therefore, the participants may be less concerned about risks and life threats, when compared to a real disaster setting. \\

Untrained participants were recruited for the field trials. We anticipate that the behaviours of players in the game may change with increased training and experience. Further, the professional responders may also behave differently because they have high a level of training, real experience of \ac{DR} operations, a different code of conduct and a distinct organisational structure.\\

In terms of data analysis, the result do not have quantitative robustness because only 6 game trials were conducted. This limitation is actually a limitation of the data analysis method we apply, namely interaction analysis. The method is extremely time consuming, thus limiting the amount of data that we can analysis \cite{Crabtree2012}. With limited trials and participants, individual difference (of participants and teams) can significantly affect the generalisability of the study results. Consequently, the generality of the results may have to be established with other means. However, this limitation does not affects the descriptive power of the qualitative approach of the analysis. \\

Overall, the PhD work employed a game approach, which has a number of limitations in terms of the game scenario, participants' altitude, participants' selection and data analysis. We cannot claim that observations of human behaviours based on a game approach would be exactly the same as what would happen in a real disasters. However, we argue that the game-based approach reproduce to some degree some critical factors of \ac{DR} operations, including time pressure, distributed teams, and mental/physical stress. Compared to computational simulation, the field trials can reveal rich human-system interactions under time and spatially constrained task conditions. Therefore, we argue that the observations from game trials are still valid and can be used to generate design implications for future automated support systems. \\


\section{future work}
Following the limitations and contributions of the thesis, its impact can be extended with future work in several possible ways. Firstly, the planning agent itself might be improved with various AI technologies. For example, the agent in this study does not consider the social cost of re-teaming and task interruption. For example, we can explore other AI technologies such as user modelling techniques (Section \ref{sec:lraisupport}) to model the human social behaviour and factor it in to the plan generation process.  However, when the agent is enhanced by new AI technologies, it is unknown whether the new capabilities would hinder or improve team coordination and how the interaction design should be adapted to support the new capabilities. Therefore, one future direction of this PhD study is to incrementally enhance agent capabilities and conduct observational studies to gain insight into the implications of the new enhancement on the interaction design.\\

Secondly, the game can be re-engineered so that the game setting can be better grounded in the real practices of disaster response team. In order to do that, the close collaboration with disaster response teams may be required. The collaboration with Global Rescue happened at a late stage of this this PhD work, and help us to identify some potential improvement of the game setting. Firstly, the targets are not always equally important. For example, human injury will typically be prioritised. Considering different weighting on targets may make the game setting more realistic. Secondly, radio rather then text messages is the communication modality normally used by operation teams, which may impact on our behaviour observations. Thirdly, AtomicOrchid assumes constant connectivity between HQ and field responders, but disaster operations are often characterised by intermittent communication. Therefore, it would also be useful to simulate the intermittent communication in AtomicOrchid.  \\

In a similar vein, the subjects of study might be changed to professional responders in order to better elucidate human behaviour in real disaster operation.  As we believe that the trained professional responders may behave differently to the general public. It would be desirable to recruit professionals in the future work to compare with the findings of this PhD study.\\

In terms of the methodology, more field trials might be conducted in order to carry out statistically robust quantitative analysis. If there are more field trials, quantitative analysis can compliment the qualitative interaction analysis in some aspects. For example, the statistical differences in terms of game results (including players death, targets saved) can be used to infer effectiveness of interaction designs. Also, the social cost and workload of the HQ might also be quantified  to give insight into the impact of interaction designs on the team performance. \\ %cognitive modelling of workload.

The studies have highlighted the trade-off between establishing common ground and information overload (Section \ref{sec:study3discussion}). It is believed that further studies can focus on exploring this the trade-off affects team coordination and developing guideline for system designers to negotiate the trade-off. \\  

Moreover, the interaction designs are not limited to on-the-loop and in-the-loop. The contribution of this PhD work can be extended by exploring some middle-ground designs. For example, the agent can be given the responsibility to decide when to perform a re-plan (as it is in the On-the-loop design), but also send the instructions to HQ for approval (as it is in the In-the-loop design).\\

It should also be noted that centralised planning support is only one kind of agent planning support technology among many. For example, planning support can also be decentralised. Planning agents could be built into personal assistant devices for every field responder. We believe that the change of agent technologies would have implications for interaction design. New interaction design patterns can be devised and adopted for changing of agent technologies. Therefore, this PhD work can potentially be extended by exploring different automated planning support technologies.\\ 

Finally, this work contributes to the research paradigm of \acf{HACS} system (Section \ref{sec:lraisupport}) by studying the interaction between one centralized planning agent and a disaster response team. However, the \ac{HACS} researchers envision a scenario in which large number of computational entities (including both software agents and embodied agents such as rescue robots) and human teams collaborate at large scale. For future work, there is a potential to extend AtomicOrchid to incorporate multiple agent and human teams to study multi-agents and human interaction.\\




